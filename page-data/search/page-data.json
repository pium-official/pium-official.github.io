{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"이 글은 우테코 피움팀 크루 '하마드'가 작성했습니다. 개요 우아한테크코스 5기 피움 서비스의 인수 테스트를 작성하던 도중, 실제 포트에 애플리케이션을 구동시켜 테스트를 하는 \n환경에서 테스트를 할 때, 테스트 메소드에서 분명히 해당 리소스를 저장했는데도 RestAssured의 GET 요청이 수행되지 않는 경우가 있었다. 이 이유를 파악하고 해결 과정을 …","fields":{"slug":"/transactional-not-in-restassured/"},"frontmatter":{"date":"July 31, 2023","title":"[트러블슈팅] @SpringbootTest의 RANDOM_PORT 환경에서 @Transactional 어노테이션을 사용했을 때, RestAssured GET 요청이 수행되지 않는 경우(트랜잭션 격리 이해하기)","tags":["Transaction","SpringbootTest"]},"rawMarkdownBody":"\n> 이 글은 우테코 피움팀 크루 '[하마드](https://github.com/rawfishthelgh)'가 작성했습니다.\n\n## 개요\n우아한테크코스 5기 피움 서비스의 인수 테스트를 작성하던 도중, 실제 포트에 애플리케이션을 구동시켜 테스트를 하는 `@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)`\n환경에서 테스트를 할 때, 테스트 메소드에서 분명히 해당 리소스를 저장했는데도 RestAssured의 GET 요청이 수행되지 않는 경우가 있었다. 이 이유를 파악하고 해결 과정을 정리한다\n## 상황\n\n![img.png](.index_images/img.png)\n\n당시 다음과 같은 인수 테스트 환경에서 테스트를 수행하고 있었다. 각 테스트 메소드가 끝난 후 트랜잭션을 롤백시켜 격리를 보장하기 위해 클래스 레벨에 `@Transactional` 어노테이션을 선언했었다.\n\n![img_1.png](.index_images/img_1.png)\n\nAcceptanceTest 클래스를 상속받아 사전 식물의 조회를 테스트하는 인수 테스트를 작성했다.\n37번째 줄의 `DictionaryPlant REQUEST = dictionaryPlantSupport.builder().build();` 는\n![img_2.png](.index_images/img_2.png)\n다음과 같은 형태로 repository에 테스트용 엔티티 객체를 save하는 과정을 간편하게 하기 위해 작성된 DictionarySupport 클래스와 코드이다. 즉 37번 라인을 사용하면 임의의 객체 정보를 dB에 저장하는 insert 작업이 일어난다.\n\n즉, 현재 테스트 메소드는 repository에 사전 식물 객체를 저장하고, 이를 RestAssured를 활용하여 실제 서버에서 요청을 보내 저장된 사전 식물이 조회되는지를 확인하는 과정이다.\n\n![img_3.png](.index_images/img_3.png)\n\n그런데, 200 OK를 기대했던 테스트의 결과가 404 not found가 응답되고 사전 식물이 존재하지 않는다는 예외 메세지가 뜨는 것을 확인하게 되었다.\n\n뭘까? insert 쿼리가 날아가지 않은 걸까? 로그를 확인해 보았다.\n![img_4.png](.index_images/img_4.png)\n그러나, 로그에는 정확히 우리가 DictionarySupport에서 지정한 저장 메소드의 Insert 쿼리가 날아가는 것을 보고 있었다. 심지어 value 값도 모두 정확히 들어갔다.\n![img_5.png](.index_images/img_5.png)\nselect 쿼리가 잘못된게 아닌가? 확인해봤지만 예상한대로 나갔다.\n여기까지 봐서는 이해가 안 간다. insert를 하고 select를 했는데 조회가 안 되니 말이다.\n## RandomPort 환경에서의 스레드와 트랜잭션\n이를 이해하기 위해서는 RandomPort 환경에서의 요청이 어떤 스레드를 갖는지를 알아야 한다. 이 내용은 스프링 공식 문서를 들여다볼 필요가 있다.\n> If your test is @Transactional, it rolls back the transaction at the end of each test method by default. However, as using this arrangement with either RANDOM_PORT or DEFINED_PORT implicitly provides a real servlet environment, the HTTP client and server run in separate threads and, thus, in separate transactions. Any transaction initiated on the server does not roll back in this case.\n\n> 테스트에 @Transactional이 붙어 있으면 롤백을 보장할 수 있다. 단, RANDOM_PORT 나 DEFINED_PORT 환경에서 테스트를 수행하면, 실제 서블릿 환경에서 테스트를 진행한다. 이 때 http 클라이언트(테스트)와 서버는 서로 다른 스레드를 갖는다. 즉 별개의 트랜잭션이 수행되는 것이다. 따라서 서버 쪽에서의 트랜잭션은 롤백되지 않는다.\n\n쉽게 설명하자면, 랜덤 포트 환경에서 테스트를 수행하는 순간, localhost 포트 어딘가에 내장 서버를 띄운다. 그리고 그 서버에서 요청을 보내도록 하는 것이 RestAssured 이다. 따라서 RestAssured에서 보내는 요청은, 내가 해당 테스트 메소드에서 실행하는 스레드와 별개의 스레드를 갖는다. 따라서 트랜잭션도 각자 별개로 갖는다.\n\n자, 아까 우리가 AcceptanceTest의 클래스 레벨에서 `@Transactional`을 선언했음을 기억할 것이다. 클래스 레벨에 이 어노테이션을 선언하면, 자동적으로 해당 클래스와 그를 상속한 메소드 레벨에 모두 트랜잭션이 걸린다.\n![img_6.png](.index_images/img_6.png)\n따라서, 현재 테스트 메소드의 트랜잭션 범위는 다음 화살표와 같이 테스트가 끝날 때 까지 유지된다.\n\n우리는 여기서 트랜잭션의 개념에 대해 다시 짚을 필요가 있다.\n\"트랜잭션이 끝나지 않았다\"는 의미는 무엇인가?\n내가 수행한 insert, update, delete 문이 커밋, 혹은 롤백되지 않았다는 뜻이다.\n\n커밋되지 않았다는 뜻은 무엇인가?\n데이터베이스의 갱신이 이뤄졌어도, 다른 스레드에서 확인할 수 없다는 뜻이다.\n왜? 트랜잭션은 각자 격리되어 서로의 트랜잭션이 끝나기 전 까지는 연산 과정을 볼 수 없기 때문이다.(트랜잭션의 Isolation(격리성) 특징을 기억하자)\n\n따라서, 현재 트랜잭션이 끝나기도 전에, 즉 반영되기도 전에 RestAssured를 통해 띄운 별개의 서버 스레드에서 GET 요청이 들어가니 해당 데이터를 확인할 수 없는 것이다.\n정확히 말하면 트랜잭션이 커밋되지 않았을 때 까지의 데이터는, 다른 스레드 입장에서 그냥 없는 데이터다. 없는걸 조회하니 당연히 값이 안 나온다.\n\n![img_7.png](.index_images/img_7.png)\n그래서 `@Transactional` 어노테이션을 제거하고 테스트를 수행했더니, 다음과 같이 통과하는 것을 볼 수 있다.\n![img_8.png](.index_images/img_8.png)\n이해를 쉽게 하기 위해 바뀐 트랜잭션의 범위를 화살표로 표현하면, DictionaryPlant를 저장하는 과정에서 트랜잭션이 끝나고 커밋이 되어 db에 영속화가 완료된다.\n따라서 이후 랜덤 포트의 스레드에서도 해당 데이터를 조회할 수 있다.\n\n\n## 트랜잭션의 격리 이해하기\n\n![img_9.png](.index_images/img_9.png)\n![img_10.png](.index_images/img_10.png)\n해당 동작에 대해 조금 더 설명하기 위해 별개의 스레드에 h2 database 콘솔을 띄워 확인해 보겠다. 위의 두 콘솔 화면은 세션 id가 다른 별개의 스레드를 갖는다. 편의상 위를 스레드A, 아래를 B라 하겠다\n\n![img_11.png](.index_images/img_11.png)\n스레드 A에서 트랜잭션을 시작하기위해 Autocommit을 False로 변경한 후, 두 명의 member 데이터를 insert 했다.\n![img_12.png](.index_images/img_12.png)\n이 때 A에서 select 문을 실행하면 데이터가 들어가 있는 것을 확인할 수 있다.\n![img_13.png](.index_images/img_13.png)\n그러나, B에서 동일한 select문을 실행하면 데이터를 확인할 수 없다.\n왜냐? 스레드 A의 트랜잭션은 끝나지 않았기 때문에 A에서 보이는 데이터는 \"임시 반영\"된 데이터일 뿐, \"영속화\"되지 않았기 때문이다.\n![img_14.png](.index_images/img_14.png)\n만약 위와 같이 스레드 A에서 커밋을 하고 나면\n![img_15.png](.index_images/img_15.png)\n이제는 스레드 B에서도 동일한 데이터를 확인할 수 있다.\n## 결론\n결국 메소드 레벨에 `@Transactional` 어노테이션이 붙은 탓에 save 메소드를 성공적으로 수행해도, 트랜잭션이 끝나지 않아(정확히 말하면 커밋되지 않아) 랜덤 포트 서버의 스레드에서 확인할 수 없는 것이다.\n따라서 랜덤 포트 환경의 격리성을 보장하고자 할 때는 `@Transactional` 어노테이션을 사용하기 보다는, truncate를 하는 sql 스크립트를 사용하는 방법을 고려하는게 더 적절하다고 생각한다.\n\n\n"},{"excerpt":"이 글은 우테코 피움팀 크루 '주노', '그레이', '조이', '하마드'가 작성했습니다. 서론 현재 피움팀 서버는  요청으로 이뤄져있다.\n는 WWW 상에서 정보를 주고 받는 프로토콜인데, 누군가 네트워크에서 신호를 가로채면 내용이 노출되는 문제가 발생할 수 있다.\n이를 해결해주는 프로토콜이 바로 이다. 는 정보를 암호화하는 SSL을 이용한 프로토콜이다. …","fields":{"slug":"/apply-https/"},"frontmatter":{"date":"July 28, 2023","title":"내 서버에 HTTPS 설정하기","tags":["HTTPS"]},"rawMarkdownBody":"\n> 이 글은 우테코 피움팀 크루 '[주노](https://github.com/Choi-JJunho)', '[그레이](https://github.com/kim0914)', '[조이](https://github.com/yeonkkk)', '[하마드](https://github.com/rawfishthelgh)'가 작성했습니다.\n\n\n## 서론\n\n현재 피움팀 서버는 `HTTP` 요청으로 이뤄져있다.\n`HTTP`는 WWW 상에서 정보를 주고 받는 프로토콜인데, 누군가 네트워크에서 신호를 가로채면 내용이 노출되는 문제가 발생할 수 있다.\n이를 해결해주는 프로토콜이 바로 `HTTPS`이다.\n\n`HTTPS`는 정보를 암호화하는 SSL을 이용한 프로토콜이다. \n현재는 TLS 방식도 사용되는데 여기에서 **핵심은 보안 문제를 해결하기 위해 암호화**를 한다는 것이다.\n\n대칭키와 공개키, 인증서와 같은 방식을 사용해 HTTPS를 적용할 수 있다.\n이번 글에서는 `Certbots`을 이용해 `HTTPS`를 nginx에 쉽게 설치하고 적용하는 방법을 다뤄본다.\n\nHTTP, HTTPS에 대한 자세한 내용은 별도의 글에서 다룰 예정이다.\n\n## Certbot 설치\n\n서버에 HTTPS 설정을 해보자\n[Certbot 공식문서](https://certbot.eff.org/)\n\n> 공식문서의 가이드를 따라 작성된 문서입니다.\n> https://certbot.eff.org/instructions\n\n![](.index_images/a8ec6c59.png)\n\n```shell\n# certbot을 설치하기 위한 snap을 설치한다.\nsudo apt update\nsudo apt install snapd\n\n# 이미 설치되어있는 certbot을 제거한다.\nsudo apt-get remove certbot\n\n# certbot을 설치한다.\nsudo snap install --classic certbot\n\n# certbot이 잘 설치되어있는지 확인한다.\nsudo ln -s /snap/bin/certbot /usr/bin/certbot\n\n# certbot을 nginx에 연결하기\nsudo certbot --nginx\n```\n## HTTPS 설정\n\n![](.index_images/5498d43a.png)\n\n```shell\n# certbot이 SSL 인증서를 자동 갱신하는 cron을 등록한다\nsudo certbot renew --dry-run\n```\n\n## NGINX 설정 확인\n\nNGINX 설정에 다음과 같이 certbot이 HTTPS 설정을 추가한 것을 확인할 수 있다.\n\n![](.index_images/3d08df23.png)\n\n## Reference\n\nhttps://certbot.eff.org/instructions\n"},{"excerpt":"이 글은 우테코 피움팀 크루 '클린'가 작성했습니다. 사건의 발단 이번 Level3 2차 데모데이때 권장사항을 맞추기 위해서 프로덕션 배포까지 진행했습니다. 어찌 저찌 배포는 잘 끝이 났는데 문제는 첫 페이지가 로드 되는데 약 4초 가량의 시간이 걸린다는 것이었습니다. 네트워크 문제 문제인가? 하고 봤는데 아니었고, 결국  파일의 크기를 보니 무려 16m…","fields":{"slug":"/bundle-analyze/"},"frontmatter":{"date":"July 28, 2023","title":"bundle-analyze를 통한 bundle 크기 분석","tags":["bundle","최적화"]},"rawMarkdownBody":"\n> 이 글은 우테코 피움팀 크루 '[클린](https://github.com/hozzijeong)'가 작성했습니다.\n\n## 사건의 발단\n\n이번 Level3 2차 데모데이때 권장사항을 맞추기 위해서 프로덕션 배포까지 진행했습니다. 어찌 저찌 배포는 잘 끝이 났는데 문제는 첫 페이지가 로드 되는데 약 4초 가량의 시간이 걸린다는 것이었습니다. 네트워크 문제 문제인가? 하고 봤는데 아니었고, 결국 `bundle.js` 파일의 크기를 보니 무려 16m나 되었던 것입니다.\n\n![image](https://github.com/pium-official/pium-official.github.io/assets/50974359/72ec258f-77e0-41aa-8bcd-c4c3d3b0410e)\n\n왜 이렇게 크기가 크지? 라는 생각을 하며 크게 2가지의 경우를 생찾아봤습니다. 하지만 다음과 같은 이유로 원인이 아님을 알았습니다.\n\n1. minify가 되지 않았다 → webpack 4 이상을 사용하면서 자동으로 `production` 일때는 자동으로 설정\n2. css 파일 크기가 너무 큼 → `styled-component`를 사용하기 때문에 .css 가 없음.\n\n따라서 `bundle.js`의 성능을 확인해 볼 필요가 있었고 검색하던 도중 [webpack-bundle-analyzer](https://www.npmjs.com/package/webpack-bundle-analyzer)라는 라이브러리를 알게되었습니다.\n\n## Webpack Bundle Analyzer\n\nwebpack을 통해 build한 bundle의 성능을 측정하는 라이브러리로 모든 번들에 대한 트리를 시각화 해서 보여주는 이점을 갖고 있습니다. 사용법은 매우 간단합니다. 우선 설치를 해줍니다.\n\n```jsx\n# NPM\nnpm install --save-dev webpack-bundle-analyzer\n# Yarn\nyarn add -D webpack-bundle-analyzer\n```\n\n설치를 한 뒤 `webpack.config.js` 파일 내부에서 플러그인을 사용해 줍니다.\n\n```jsx\nconst BundleAnalyzerPlugin = require('webpack-bundle-analyzer').BundleAnalyzerPlugin;\n\nmodule.exports = {\n  plugins: [\n    new BundleAnalyzerPlugin()\n  ]\n}\n```\n\n플러그인 안에 옵션을 설정할 수 있는데, [여기](https://github.com/webpack-contrib/webpack-bundle-analyzer#options-for-plugin)에서 옵션에 대한 정보를 확인할 수 있습니다.\n\n위에 플러그인 옵션에서 `generateStatsFile` 을 `true` 로 설정한 다음에 `package.json`에 `scripts` 에다음 명령어를 통해 실행할 수 있습니다.\n\n```jsx\nanalyze: webpack-bundle-analyzer bundle/output/path/stats.json\n```\n\n![image](https://github.com/pium-official/pium-official.github.io/assets/50974359/6bc524c4-4866-4ebe-9daa-95035e0c0dd5)\n\n실행한 뒤에 bundle을 분석해 봤더니 react-icons에서 15.3m나 차지하고 있었습니다. 드디어 문제의 원흉을 찾아냈습니다. 그렇다면 react-icons를 대체할 수 있는 방법이 있을까요?\n\n### Icons\n\n[여기](https://icones.js.org/collection/all?s=material-symbols:cancel)에 가시면 다양한 아이콘들을 찾아볼 수 있습니다. 원하는 아이콘을 선택한 다음에 SVG, Component 등으로 코드를 반환해 줍니다. 이를 통해서 react-icons를 제거하고 icons를 사용해서 아이콘을 대체할 수 있었습니다.\n"},{"excerpt":"이 글은 우테코 피움팀 크루 '주노', '그레이', '조이', '하마드'가 작성했습니다. 서론 본 설명 글은 다음과 같은 환경에서 진행됩니다. 배포서버 : Ubuntu 22.04.2 LTS DB서버 : Ubuntu 22.04.2 LTS 배포서버와 DB서버는 동일한 VPC를 사용하고 있습니다. DB : MySQL 8.0.33 Application : Spr…","fields":{"slug":"/db-drop-stop/"},"frontmatter":{"date":"July 28, 2023","title":"Table Drop 못하게 막아버리기","tags":["DB","MySQL"]},"rawMarkdownBody":"\n> 이 글은 우테코 피움팀 크루 '[주노](https://github.com/Choi-JJunho)', '[그레이](https://github.com/kim0914)', '[조이](https://github.com/yeonkkk)', '[하마드](https://github.com/rawfishthelgh)'가 작성했습니다.\n\n\n## 서론\n\n본 설명 글은 다음과 같은 환경에서 진행됩니다.\n> - 배포서버 : Ubuntu 22.04.2 LTS\n> - DB서버 : Ubuntu 22.04.2 LTS\n> - 배포서버와 DB서버는 동일한 VPC를 사용하고 있습니다.\n> - DB : MySQL 8.0.33\n> - Application : SpringBoot 3.1.1\n\n개발 과정에서 실수로 Application 단에서 DB 혹은 테이블을 Drop 해버리는 상황이 있을 수 있다.\n\n테이블의 수정이 제한된 유저를 생성하여 해당 유저를 Application에서 사용하도록 구성해보자. \n\n> 도움을 주신 G선생님께 감사의 인사 올리며 시작하겠습니다.\n> \n> ![](.index_images/c34a6c3a.png)\n\n## 유저 생성하기\n\n> 이후 진행할 작업에서 권한 부여를 위해 root 권한이 필요합니다.\n\n우선 root 권한을 가진 계정으로 MySQL에 로그인 한다.\n\n```shell\n# MySQL에 로그인\nsudo mysql -u root -p\n```\n\nApplication에서 사용할 유저를 생성한다.\n\n```sql\nCREATE USER 'pium'@'localhost' IDENTIFIED BY 'password';\n```\n\n> 만약 외부에서 접근해야하는 유저의 경우 다음 명령어를 참고하세요\n> \n> ```sql\n> # 외부 모든 IP에 대한 pium 이라는 유저 생성 \n> CREATE USER 'pium'@'%' IDENTIFIED BY 'password';\n> \n> # 특정 인스턴스에서만 접속가능한 pium 이라는 유저 생성 \n> CREATE USER 'pium'@'접속할 인스턴스의 private ip' IDENTIFIED BY 'password';\n> ```\n\n## 권한 부여하기\n\nMySQL에서 설정할 수 있는 권한은 아래와 같다.\n\n| 권한                | 내용                     |\n|-------------------|------------------------|\n| CREATE, ALTER, DROP | 테이블 생성, 변경, 삭제  |\n| SELECT, INSERT, UPDATE, DELETE | 테이블의 레코드 조회, 입력, 수정, 삭제 |\n| RELOAD| 권한 부여된 내용을 리로드 |\n| SHUTDOWN| 서버 종료 작업 실행 |\n| ALL| 모든 권한 허용 |\n| USAGE| 권한 없이 계정만 생성 |\n\n우리는 `INSERT`, `UPDATE`, `SELECT`, `DELETE`만 사용하면 되기 떄문에, 새로 생성한 유저에게 해당 권한만 부여한다.\n\n```sql\nGRANT SELECT, INSERT, UPDATE, DELETE ON pium_db.* TO 'pium'@'localhost';\n```\n\n설정한 권한을 `flush` 명령어를 이용해 적용한다.\n\n```sql\nFLUSH PRIVILEGES;\n```\n\n## 확인하기\n\n![](.index_images/bd8e631c.png)\n\n실제로 생성된 유저로 접속하여 Drop Table 명령어를 수행했을 때 권한 부족으로 수행되지 않음을 확인할 수 있다.\n\n## Application properties 적용\n\nApplication의 설정파일에 생성한 유저의 정보를 작성한다.\n\n![](.index_images/54161808.png)\n\n이를 통해 Applicaiton에서는 Table의 생성, 수정, 삭제에 대한 조작을 할 수 없게 되었다.\n\n만약 테이블의 생성, 수정, 삭제에 대한 작업이 필요할 경우 DBA 혹은 DB 담당자에게 요청하는 프로세스를 거쳐야만 한다.\n\n## Reference\n\n- Chat GTP 4\n- 피움 백엔드 팀의 집단지성\n"},{"excerpt":"이 글은 우테코 피움팀 크루 '주노'가 작성했습니다. 서론 현재 피움팀의 젠킨스에서 빌드 트리거로 을 사용하고있다.  해당 설정은 Github에서 유발되는 모든 WebHook에 대해 빌드 트리거가 동작하는 설정이다.  빌드 스크립트에서 위처럼 triggers 설정을 별도로 지정할 수 있지만 현재 프로젝트 구조상 더 세분화된 설정이 필요한 상태다.  현재 …","fields":{"slug":"/jenkins-hook-by-label/"},"frontmatter":{"date":"July 25, 2023","title":"PR 라벨로 젠킨스 빌드유발을 구분하기","tags":["젠킨스","CD"]},"rawMarkdownBody":"\n> 이 글은 우테코 피움팀 크루 '[주노](https://github.com/Choi-JJunho)'가 작성했습니다.\n\n## 서론\n\n현재 피움팀의 젠킨스에서 빌드 트리거로 `GitHub hook trigger for GITScm polling`을 사용하고있다.\n\n![](.index_images/bc288fb6.png)\n\n해당 설정은 Github에서 유발되는 모든 WebHook에 대해 빌드 트리거가 동작하는 설정이다.\n\n![](.index_images/c0a90061.png)\n\n빌드 스크립트에서 위처럼 triggers 설정을 별도로 지정할 수 있지만 현재 프로젝트 구조상 더 세분화된 설정이 필요한 상태다.\n\n![](.index_images/b47bf110.png)\n\n현재 레포지토리 하나에 프론트, 백엔드 코드가 같이 관리되고있다.\nPR이 Merge 되었을 때 각 트랙별로 코드가 빌드 및 배포될 수 있도록 구성해야한다.\n\n## 어떻게 할까?\n\n현재 하나의 레포지토리에서 두개의 코드가 관리되고 있기 떄문에 단순히 develop 브랜치의 변경감지로는 어느 트랙의 작업내용인지 구분하기가 어렵다.\n\n![](.index_images/88fd7187.png)\n\n현재 피움은 라벨을 이용하여 트랙별 작업구분을 하고 있다.\n\n이를 이용하여 라벨별로 빌드, 배포를 진행할 수 있도록 구성해보자.\n\n## Generic Webhook Trigger 설치\n\n![](.index_images/82e40c68.png)\n\nGeneric Webhook Trigger는 젠킨스에서 제공하는 플러그인으로 HTTP 요청을 수신하여 JSON, XML 형태의 데이터를 추출하여 트리거를 지정할 수 있는 플러그인이다.\n\nGeneric Webhook Trigger를 사용하여 빌드 유발 상황을 구분해보자.\n\n![](.index_images/4ff8e063.png)\n\n플러그인을 설치했다면 파이프라인의 Build Triggers 설정에서 다음과 같은 탭을 확인 할 수 있다.\n\n![](.index_images/7b51b24a.png)\n\n해당 설정을 클릭해보면 다음과 같은 설명을 확인할 수 있다.\n\n`http://JENKINS_URL/generic-webhook-trigger/invoke` 로 오는 요청에 대해 트리거가 수행된다는 말이 적혀져있다.\n\n위 설명에 맞춰 GitHub에서 WebHook 설정을 변경해주자.\n\n> 위에서 설명한 탭에 대해서는 아직 저장하지않고 깃허브로 넘어와서 진행합니다.\n>\n> 젠킨스 설정은 아래에서 설명하는 `Github WebHook 설정`이후 이어서 진행합니다.\n\n## Github WebHook 설정\n\n![](.index_images/eebe67d7.png)\n\n`프로젝트 레포지토리` -> `Settings` -> `Webhooks 탭`에 들어와서 웹훅을 새로 만들어보자.\n\n![](.index_images/19691acb.png)\n\nPayload URL을 위에서 확인한 `Generic Webhook Trigger`의 설정에 맞게 작성한다.\n\n그리고 트리거가 동작하는 이벤트에 대해서 `Send me everything` 옵션을 체크한다.\n\n![](.index_images/5e2c402b.png)\n\nAdd webhook을 한 뒤 다시 등록한 웹 훅을 클릭하여 `Recent Deliveries` 탭을 확인해본다.\n\n![](.index_images/bb813e21.png)\n\n내용을 보면 요청을 보낼 때 Payload에 다양한 정보들이 담겨있는 것을 확인할 수 있다.\n\n### (이해하기) JSONPath 살펴보기\n\n> 해당 과정은 원리를 이해하기 위한 과정으로 수행하지 않아도 무관합니다.\n\n![](.index_images/4ff6a8c1.png)\n![](.index_images/f6916224.png)\n\nPR과 연관된 요청이 발생했을 때는 Payload에 pull_request에 대한 정보가 추가된다.\n\n![](.index_images/c301431e.png)\n\nhttps://jsonpath.com 에 접속하여 해당 Payload를 붙여넣어 확인해본다.\n\nJSONPath로 표현했을 때 `$.pull_request.merged`를 확인하면 해당 요청이 PR이 merge된 요청인지 확인할 수 있다.\n\n![](.index_images/0d6d400d.png)\n\n`$.pull_request.base.ref`는 해당 PR의 base 브랜치를 의미한다.\n\n예를들어 feature -> develop 형태라면 develop이 나온다\n\n![](.index_images/47afaad7.png)\n\n`$.pull_request.labels..name`는 해당 PR의 라벨들의 이름을 의미한다.\n\n## Generic Webhook Trigger 설정\n\n> ![](.index_images/5b94c679.png)\n파이프라인 설정 구성에 들어와서 작업을 이어나갑니다.\n\n![](.index_images/f9141614.png)\n\n기존에 설정해둔 `GitHub hook trigger for GITScm polling` 설정을 해제한다.\n\n![](.index_images/40676eae.png)\n\n그리고 Generic WebHook Trigger 를 활성화한다.\n\n### Post content parameters 설정\n\n`Post content parameters`의 추가 버튼을 눌러 파라미터를 추가한다.\n\n![](.index_images/f66fbb52.png)\n\n`$.pull_request.merged`를 등록하여 Merge 되었는지 여부를 가져온다.\n\n![](.index_images/2f09a4a8.png)\n\n`$.pull_request.base.ref`를 등록하여 base 브랜치를 가져온다.\n\n원하는 값은 develop 브랜치가 될 것이다.\n\n![](.index_images/d7a4b4fc.png)\n\n`$.pull_request.labels..name`를 등록하여 라벨들의 이름을 가져온다.\n\n원하는 값은 등록된 라벨들 중에 `백엔드`를 포함하는 값이 존재하는 상황이 될 것이다.\n\n### Optional filter 설정\n\n아래로 내리다보면 Optional filter 탭을 볼 수 있다.\n\n![](.index_images/3f3d0f71.png)\n\nExpression에 다음과 같은 정규표현식을 작성했다.\n\n`(?=.*true)(?=.*develop)(?=.*백엔드).*`\n\n또한 Text 부분에는 위에서 파라미터로 선언한 값들을 사용했다.\n\n위 표현식으로 다음과 같은 효과를 기대할 수 있다.\n\n`merge가 true 이고`, `브랜치가 develop 이고`, `라벨에 백엔드가 존재`하는 작업에 대해 트리거를 수행하는것을 기대할 수 있다.\n\n### Token 설정\n\n![](.index_images/b55101b4.png)\n\nToken 탭에 토큰 이름을 작성한다.\n\n![](.index_images/8e4baf8e.png)\n\n이 때 GitHub WebHook 설정에 들어가서 Payload URL에 token 파라미터를 포함하도록 수정한다.\n\n![](.index_images/675ca490.png)\n\n바로 아래 탭에서 TokenCredential에 토큰에 대한 Secret Key를 추가해줘야한다.\n\n외부에서 빌드를 유발하기 위해서는 token을 확인하는 방식이 존재하는데 이 때 Jenkins의 Credential에 있는 정보를 기반으로 수행한다.\n\n> token을 사용하지 않는 경우 계정정보를 입력할 수도 있지만 해당 과정에서는 token을 등록하는 방식을 사용합니다.\n\n![](.index_images/639919be.png)\n\n위와 같은 정보로 Secret text를 작성하고 등록하고 적용한다.\n\n## 응답 확인하기\n\n![](.index_images/8f20f94d.png)\n\nGitHub의 WebHook 탭의 Recent Deliveries 탭으로 가서 확인해보면 Response Body값에 다음과 같은 응답이 담겨있는 것을 확인할 수 있다.\n\n```json\n{\n  \"jobs\": {\n    \"pium-dev\": {\n      \"regexpFilterExpression\": \"(?=.*true)(?=.*develop)(?=.*백엔드).*\",\n      \"triggered\": true,\n      \"resolvedVariables\": {\n        \"BRANCH\": \"develop\",\n        \"LABELS\": \"[\\\"?️ \\\\b리팩터링\\\",\\\"? 백엔드\\\"]\",\n        \"LABELS_0\": \"?️ \\b리팩터링\",\n        \"LABELS_1\": \"? 백엔드\",\n        \"MERGED\": \"true\"\n      },\n      \"regexpFilterText\": \"true develop [\\\"?️ \\\\b리팩터링\\\",\\\"? 백엔드\\\"]\",\n      \"id\": 248,\n      \"url\": \"queue/item/248/\"\n    }\n  },\n  \"message\": \"Triggered jobs.\"\n}\n```\n\n`regexpFilterText`에 원하는 값이 잘 들어간 것을 확인할 수 있다.\n\n## 결론\n\n젠킨스의 `Generic Webhook Trigger` 플러그인을 이용하여 Merge 여부, target branch, label 값을 비교하고 빌드를 유발하는 설정을 했다.\n\n경우에 따라 세부적인 검증을 추가할 수 있을 것 같다.\n\n### 트러블 슈팅\n\nGeneric Webhook Trigger 설정 - Token 설정에서 많이 헤맸다.\n\n![](.index_images/1c588600.png)\n\n`{\"jobs\":null,\"message\":\"Did not find any jobs with GenericTrigger configured! If you are using a token, you need to pass it like ...trigger/invoke?token=TOKENHERE. If you are not using a token, you need to authenticate like http://user:passsword@example.org/generic-webhook... \"}`\n\n404 에러와 함께 위 메시지가 반환되었는데 Jenkins의 Token에 대해 이해를 하지 못해 생긴 문제였다.\n\n> 왜 다들 Token이 뭔지는 설명을 안해주는거지..?? ㅠㅠ\n>\n> `외부에서 빌드를 유발하기 위해서는 token을 확인하는데 이 때 Jenkins의 Credential에 있는 정보를 기반으로 수행한다.`\n>\n> 이 한마디를 이해하기 위해 하루가 걸렸다... 😇\n\n## Reference\n\n### 설정 과정에서 참고한 글\n\nhttps://bepoz-study-diary.tistory.com/385\n\nhttps://velog.io/@zayson/Jenkins-CICD-4.-WebHook%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%9E%90%EB%8F%99-%EB%B0%B0%ED%8F%AC\n\n\n### 트러블 슈팅 과정에서 참고한 글\n\nhttps://georgik.rocks/jenkins-generic-webhook-plugin-failed-with-did-not-find-any-jobs-with-generictrigger-configured/\n\nhttps://pikachu987.tistory.com/61"},{"excerpt":"이 글은 우테코 피움팀 크루 '그레이'가 작성했습니다. 이번 피움 서비스에서 CI/CD를 적용하기 위해 Jekins와 Github Webhook을 이용했습니다. 본 글에서는 Jenkins와 Github Webhook을 이용한 SpringBoot 서버 자동 빌드, 자동 배포 과정을 다루겠습니다. Jenkins 설치 과정은 피움 팀 젠킨스 설치하기 를 참고하…","fields":{"slug":"/ci-cd-setting/"},"frontmatter":{"date":"July 24, 2023","title":"Jenkins와 Github Webhook을 이용해 CI/CD 구축하기","tags":["CI/CD","젠킨스","Webhook","설정"]},"rawMarkdownBody":"\n> 이 글은 우테코 피움팀 크루 '[그레이](https://github.com/Kim0914)'가 작성했습니다.\n\n이번 피움 서비스에서 CI/CD를 적용하기 위해 Jekins와 Github Webhook을 이용했습니다.\n\n\n\n본 글에서는 Jenkins와 Github Webhook을 이용한 SpringBoot 서버 자동 빌드, 자동 배포 과정을 다루겠습니다.\n\n\n\nJenkins 설치 과정은 [피움 팀 젠킨스 설치하기](https://pium-official.github.io/jenkins-setting/) 를 참고하시면 됩니다 !\n\n\n\n작업 환경\n\n- 인스턴스: AWS EC2 t4g.small\n- OS: Ubuntu 22.04.2 LTS\n- RAM: 2GB\n\n\n## Jenkins 접속\n젠킨스를 접속하는 방법은 간단합니다. 젠킨스를 설치한 인스턴스 public IP와 port를 주소창에 입력하면 쉽게 접근할 수 있습니다.\n\n\n\n정상적으로 접속하면 다음과 같은 화면을 만나게 됩니다.\n![](.index_images/img.png)\n\n---\n## Github Webhook 설정\n먼저 Webhook을 설정하기 위해 현재 프로젝트의 깃허브 레포지토리로 이동합니다.\n\n\n\n레포지토리의 Settings를 눌러서 접속할 수 있습니다. 이후 왼쪽 메뉴바에 Webhooks를 누르면 아래와 같은 화면을 볼 수 있습니다.\n![](.index_images/img_1.png)\n\n오른쪽 상단의 Add Webhook 버튼을 눌러 webhook을 추가하는 화면으로 이동합니다.\n\n\n\n그러면 아래와 같은 Payload URL, Content Type, Secret을 입력하는 폼이 나타납니다.\n![](.index_images/img_2.png)\n\n**Payload URL**은 젠킨스가 설치되어 있는 서버의 `도메인 주소:포트/github-webhook/` 을 입력합니다.\n\n젠킨스의 기본 포트는 8080으로 설정되어 있습니다.\n\n주소 마지막에 / 는 꼭 넣어주셔야 합니다.\n\n/를 넣지 않으면 redirect URL로 인식해 정상적으로 동작하지 않습니다.\n\n\n\n**Content-type**은 `application/json`을 선택합니다.\n\n\n\nSecret은 비워두면 됩니다.\n\n\n\n마지막으로 어떤 동작에서 webhook을 발생시킬지 선택하면 됩니다.\n\n저희 팀의 경우에는 **Let me select individual events**를 눌러 **push**와 **pull request**가 발생했을 때 webhook이 동작하도록 선택했습니다.\n\n\n\n모든 선택을 마친 후 **Add webhook 버튼을 누르면 토큰이 발행**됩니다.\n\n\n\n토큰을 생성할 때 토큰 권한도 함께 설정할 수 있는데, 이 때 repo와 admin:repo_hook을 선택해주시면 됩니다.\n\n\n\n만약 CI를 통해 PR에 comment를 남기는 등의 write가 필요없는 경우에는 wirte 권한을 빼줄 수 있을 것 같습니다.\n\n\n\n해당 토큰은 생성 후 재발행되지 않기 때문에 따로 보관을 하는 것이 좋습니다.\n\n---\n## Credentials 생성\n다시 젠킨스 화면으로 이동해서 Credentials를 등록하여 Github webhook을 연동 시켜야 합니다.\n\n\n\n젠킨스 메인 화면에서 Jenkins 관리 페이지로 접속하면 Security 탭에 Credentials를 눌러 접속합니다.\n![](.index_images/img_3.png)\n\nAdd Credentials를 누릅니다.\n![](.index_images/img_4.png)\n\n그러면 아래와 같은 화면을 볼 수 있습니다.\n\n\n\n깃허브 webhook에서 발급받은 토큰을 이용해 크리덴셜 값을 생성합니다.\n![](.index_images/img_5.png)\n\n**kind**는 `Username with password`를 선택합니다.\n\n\n\n**username**에는 깃허브 토큰을 발급받은 `깃허브 아이디`를 작성합니다.\n\n\n\n**password**에는 `해당 토큰 값`을 넣으면 됩니다.\n\n\n\n**ID**는 젠킨스에서 이 **크리덴셜을 식별하기 위한 이름이므로 크게 의미가 없는 값** 입니다.\n\n---\n### Gradle 설정\n현재 우리 팀은 스프링 부트 서버를 빌드하기 때문에 gradle이 반드시 필요합니다.\n\n\n\n젠킨스 메인 화면에서 대시보드 -> 젠킨스 관리 -> Tools를 누르면 아래와 같은 Gradle 설정 화면을 볼 수 있습니다.\n![](.index_images/img_6.png)\n\nGradle 8.2.1 버전을 추가했습니다.\n\n추가를 완료하고 바로 페이지를 나가면 안됩니다.\n\n가장 아래에 있는 파란색 save 버튼을 눌러야 해당 설정이 저장됩니다 !!\n\n\n\nGradle 설정까지 마치면 빌드할 준비를 모두 마쳤습니다.\n\n\n\n이제 CI를 자동으로 실행하기 위해서는 CI 스크립트를 작성해야 합니다.\n\n---\n## CI 스크립트 작성\n드디어 CI를 담당하는 젠킨스 아이템을 생성할 시간입니다 !\n\n\n\n대시보드에서 New Item을 누르면 아래와 같은 화면을 볼 수 있습니다.\n![](.index_images/img_7.png)\n\n상단에 아이템 이름을 설정하고 Pipeline을 구축할 것이기 때문에 Pipeline을 선택하고 OK를 누릅니다.\n\n\n\n이후 아래와 같이 아이템을 설정할 수 있는 화면이 나옵니다.\n![](.index_images/img_8.png)\n\n저희는 깃허브 프로젝트를 사용하고 있기 때문에 Github Project를 체크한 후 레포지토리의 url을 입력합니다.\n\n\n\n다음으로 Build Trigger를 선택해야하는데, Github webhook을 사용할 계획이므로 Github hook triger for GITScm polling을 선택합니다. 해당 버튼을 클릭하면 아래에 스크립트를 작성하는 칸이 나옵니다.\n![](.index_images/img_9.png)\n\n\n\nScript칸에 팀에서 필요로 하는 CI Script를 입력하면 됩니다.\n\n\n\n여기서 저장 버튼 위에 보이는 Pipeline Syntax를 누르면 깃허브를 이용해 접근할 수 있는 스크립트를 생성하는 화면이 나옵니다.\n![](.index_images/img_10.png)\n\nSample Step을 Git으로 설정한 후 아래에 값을 입력하면 됩니다.\n\n\n\nCredentials에는 좀 전에 생성했던 크리덴셜을 선택하면 됩니다. 해당 정보에 토큰 값이 있기 때문에 정확한 크리덴셜을 선택해야 합니다.\n\n크리덴셜은 생성할 때 입력한 ID와 동일하게 보여집니다.\n\n\n\n모두 입력했다면 Generate Pipeline Script를 눌러 완성된 스크립트를 확인합니다.\n\n\n\n해당 스크립트를 만드는 이유는 빌드 과정에서 Github 저장소에서 저장소를 복제해야하기 때문입니다.\n\n그러므로 저장소에 대한 접근 권한이 반드시 필요합니다.\n\n\n\n전체 빌드 스크립트는 아래와 같습니다.\n\n```shell\npipeline {\n    agent any\n    tools {\n        gradle 'gradle'\n    }\n    triggers {\n        githubPush()\n    }\n    stages {\n        stage('저장소 복제') {\n            steps {\n                // 여기서 방금 생성된 깃허브 스크립트 넣기\n        }\n        \n        stage('빌드') {\n            steps {\n                sh '''\n                cd backend/pium\n                ./gradlew clean build\n                '''\n            }\n            post {\n                failure {\n                    slackSend (\n                        channel: '#알림-젠킨스',\n                        color: '#FF0000',\n                        message: \"백엔드 Build 실패...😢\"\n                    )\n                }\n            }\n        }\n    }\n}\n```\n\n\nstages에서 깃허브 저장소에 있는 프로젝트를 가져온 후, 본인의 프로젝트 디렉토리로 이동해 build를 진행하도록 하면 됩니다.\n\n디렉토리를 옮기는 부분에서 몇 번 에러가 있었는데, Jenkins 대시보드의 Console Output을 이용해 디버깅하면서 수정해나가면 쉽게 설정할 수 있습니다.\n\n\n\n지금까지 올바르게 적용되었다면 CI 설정은 모두 정상적으로 마쳤습니다.\n\n\n\n다음으로 CD(자동 배포) 설정 방법을 알아보겠습니다.\n\n---\n## SSH Agent 설치\n현재 빌드 서버와 운영 서버가 서로 다른 인스턴스로 분리되어 있기 때문에, 젠킨스 빌드 서버에서 빌드한 파일을 운영서버로 전달해야\n\n합니다. 이때 다른 인스턴스로의 접속이 필요하므로 SSH 연결 설정을 해야 합니다.\n\n\n\n기존의 블로그나 여러 레퍼런스를 찾아보면 Publish Over SSH를 많이 사용하는데, 현재 접속 불가 이슈가 있습니다.\n\n그러므로 SSH Agent를 사용해야 합니다.\n\n\n\nJenkins 관리의 Plugin 탭을 들어가서 설치할 수 있습니다.\n\n\n\nJenkins도 하나의 서버에서 동작하고 있기 때문에 운영서버로 접속하기 위한 pem 키가 필요합니다.\n\n\n\n대시보드 -> 젠킨스 관리 -> Credentials 로 이동합니다.\n\n\n\n깃허브 크리덴셜을 생성하는 것과 동일한 방법으로 pem 키를 크리덴셜로 설정합니다.\n![](.index_images/img_11.png)\n\n**kind**는 `SSH Username with private key`를 선택합니다.\n\n\n\n**id**는 깃허브 크리덴셜과 마찬가지로 식별자이기 때문에 `원하는 값을` 입력하면 됩니다.\n\n\n\n**username**은 인스턴스의 HostName ex) ubuntu@123-345-678-23의 `ubuntu` 를 입력하면 됩니다.\n\n\n\n마지막으로 **인스턴스를 생성하면서 받았던 pem 키를 Add 버튼을 눌러 추가**합니다.\n\npem 키에 있는 모든 내용(Begin, End 포함)을 다 복사해서 넣어야합니다.\n\n---\n## CD 스크립트 작성\n이제 젠킨스가 설치된 서버에서 빌드된 결과물을 운영 서버로 전달하는 스크립트를 작성해야 합니다.\n\n이때 scp 라는 프로토콜을 사용하여 파일을 전달합니다.\n\n\n\n저희 팀이 사용한 스크립트는 아래와 같습니다.\n\n빌드 성공 유뮤, 배포 성공 유무를 슬랙과 연동해 사용하고 있습니다 !\n\n```shell\npipeline {\n    agent any\n    tools {\n        gradle 'gradle'\n    }\n    triggers {\n        githubPush()\n    }\n    stages {\n        stage('저장소 복제') {\n            steps {\n                // 깃허브 크리덴셜\n            }\n        }\n        \n        stage('빌드') {\n            steps {\n                sh '''\n                cd //프로젝트 위치\n                ./gradlew clean build\n                '''\n            }\n            post {\n                failure {\n                    slackSend (\n                        channel: '#알림-젠킨스',\n                        color: '#FF0000',\n                        message: \"백엔드 Build 실패...😢\"\n                    )\n                }\n            }\n        }\n        stage('배포') {\n            steps {\n                sshagent(credentials: ['pem 키로 생성한 크리덴셜 ID']) {\n                    sh '''\n                        cd //프로젝트 위치\n                        \n                        ssh -o StrictHostKeyChecking=no {HostName}@{Private IP} uptime\n                        cd build/libs\n                        \n                        scp {빌드된 Jar 파일명} {HostName}@{Private IP}:/home/ubuntu\n                        ssh -t {HostName}@{Private IP} {운영서버 배포 스크립트 파일}\n                    '''\n                }\n            }\n            post {\n                success {\n                    slackSend (\n                        channel: '#알림-젠킨스',\n                        color: '#00FF00',\n                        message: \"백엔드 배포 성공! 🚀\"\n                    )\n                }\n                failure {\n                    slackSend (\n                        channel: '#알림-젠킨스',\n                        color: '#FF0000',\n                        message: \"백엔드 배포 실패 🥲\"\n                    )\n                }\n            }\n        }\n    }\n}\n```\n\n\nCI/CD 설정을 모두 마친 후 깃허브 프로젝트에 push, pull request와 같은 trigger가 발생하면 아래와 같이 빌드 결과를 볼 수 있습니다.\n![](.index_images/img_12.png)\n\n### Reference\n[베베의 CI/CD 글](https://developer-nyong.tistory.com/47#article-7-1--ssh-%ED%94%8C%EB%9F%AC%EA%B7%B8%EC%9D%B8-%EC%84%A4%EC%B9%98)\n"},{"excerpt":"이 글은 우아한테크코스 5기, 피움팀 크루 '참새'가 작성했습니다. 서론  피움의 프론트엔드에서는 서버 상태 관리를 위해 Tanstack Query를 사용하기로 하였다. 이 글에서는 많고 많은 상태 관리 라이브러리 중 Tanstack Query를 사용하기로 결정한 이유를 소개하고자 한다. 설치한 버전: 5.0.0-alpha.86 Tanstack query…","fields":{"slug":"/fe-tanstack-query/"},"frontmatter":{"date":"July 23, 2023","title":"프론트엔드: Tanstack Query 사용에 대하여","tags":["Tanstack Query","React Query","리액트 쿼리"]},"rawMarkdownBody":"\n> 이 글은 우아한테크코스 5기, 피움팀 크루 '[참새](https://github.com/WaiNaat)'가 작성했습니다.\n \n\n## 서론\n\n![Tanstack: High-quality open-source software for web developers. Headless, type-safe, and powerful utilities for state management, routing, data visualization, charts, tables, and more.](.index_images/tanstack.png)\n\n피움의 프론트엔드에서는 서버 상태 관리를 위해 [Tanstack Query](https://tanstack.com/query/v5/docs/react/overview)를 사용하기로 하였다.\n\n이 글에서는 많고 많은 상태 관리 라이브러리 중 Tanstack Query를 사용하기로 결정한 이유를 소개하고자 한다.\n\n> 설치한 버전: 5.0.0-alpha.86\n\n## Tanstack query로 얻을 수 있는 개발적인 이점\n\n### 코드 간소화와 컴포넌트의 관심사 분리\n\nTanstack query에서 제공하는 다양한 함수들을 활용하면 비동기 통신의 처리 코드를 선언형으로 만들 수 있다. 또한 Tanstack query가 서버와의 통신을 대신해주기 때문에 컴포넌트의 렌더링 함수는 UI/UX의 구현이라는 보다 근본적인 내용에 집중할 수 있다. 조금 더 풀어서 설명하면 네 가지로 나눌 수 있다.\n\n우선 `<Suspense>`와 `<ErrorBoundary>`의 편한 사용이 가능하다. 이 둘을 사용하기 위해서는 각각 promise 또는 error를 throw하는 과정이 필요하다. 특히 error가 아닌 것을 던진다는 생각은 기존의 틀을 깨는 것으로 (eslint에 [관련 설정](https://eslint.org/docs/latest/rules/no-throw-literal)이 있다는 점으로 미루어 볼 때 자주 사용하는 기법이 아니었을 것이다) 새로운 코드를 짜야 한다. [Suspense를 설명하는 리액트 공식 문서](https://react.dev/reference/react/Suspense#displaying-a-fallback-while-content-is-loading)의 첫 번째 예제에서 Fork를 눌러 `Albums.js`안의 `use()`함수를 보면 promise를 던지기 위해 굉장히 재미있는 기법을 사용하고 있다는 걸 확인할 수 있다. 이러한 일련의 과정을 tanstack query가 대신하기 때문에 편리한 사용이 가능하다.\n\n다음으로 낙관적 업데이트를 적용하기에 유리하다. `useMutation`의 `onSuccess`, `onError`, `onSettled`와 같은 설정을 이용하면 된다.\n\n세 번째로는 비동기 통신의 결과 타입을 자동으로 추론해준다는 점이다. 따라서 컴포넌트 내부에서 불필요한 타입 가드 및 추론, 강제 타입 지정과 같은 행동을 하지 않아도 되므로 타입스크립트를 더 깔끔하게 사용할 수 있다.\n\n마지막으로 서버 상태 처리를 위한 전역 상태 관리 라이브러리를 도입하지 않아도 된다. 물론 이건 비단 tanstack query만의 장점은 아니다. 하지만 캐싱을 이용해서 전역 상태를 이용하지 않고도 여러 컴포넌트에서 같은 쿼리를 요청했을 경우 추가적인 통신 없이도 정보를 전달받을 수 있다는 점은 매력적이다.\n\n### 비동기 통신\n\n1. 캐싱을 지원하기 때문에 서버와의 불필요한 통신을 줄일 수 있다.\n2. 다양한 상황에서 자동 refetch가 가능해서 원한다면 항상 최신 값을 유지할 수 있다.\n3. 여러 컴포넌트가 같은 쿼리를 사용할 때, 해당 쿼리로부터 반환되는 데이터가 바뀌었다면 그 컴포넌트들을 한 번에 업데이트할 수 있다.\n4. 쿼리가 오랫동안 사용되지 않으면 가비지 컬렉터를 자동으로 불러서 정리한다.\n\n## 다른 라이브러리와의 비교\n\n우리 팀에서는 Recoil 이외의 다른 전역 상태 라이브러리나 서버 상태 라이브러리를 사용해본 경험이 많은 크루가 없어서 간단하게만 비교하였다.\n\n### [SWR](https://github.com/vercel/swr)\n\nNext.js 팀에서 만든 서버 상태 관리 라이브러리. 데이터 캐싱이라는 측면에 집중했다. 따라서 다른 라이브러리와 비교했을 때 굉장히 가벼운 편에 속한다.\n\n### [Tanstack Query](https://tanstack.com/query/v5/docs/react)\n\n데이터 캐싱뿐만이 아니라 에러 처리나 무한 스크롤과 같은 다양한 기능을 지원한다. 비슷한 기능을 하는 리액트 쿼리의 [`useQuery`](https://tanstack.com/query/v5/docs/react/reference/useQuery)와 SWR의 [`useSWR`](https://swr.vercel.app/docs/data-fetching)의 반환값을 확인해보았을 때 받을 수 있는 정보의 양이 차이가 많이 난다. 다양한 상황을 고려한 UI를 보여준다면 Tanstack query를 활용하는 것이 좋겠다는 생각을 했다. 추가적으로 받아온 데이터의 일차 가공이 필요하다면 `useQuery`에서 `selector`를 사용할 수 있다는 점도 상대적인 장점이라고 생각한다.\n\n### Redux, Recoil 등 다른 전역 상태 관리 라이브러리\n\n현재 피움 서비스 내에서 전역적으로 관리할 값이 많지 않다고 판단하였다.\n\n또한 일반적인 전역 상태 라이브러리의 경우 서버 상태를 나타나기에는 부적절한 것 같다. 특히 Recoil은 selector의 캐시 문제로 인해 사용자의 장바구니 목록처럼 자주 변하는 값을 받아오기 굉장히 힘들었던 기억이 있다.\n\n## Tanstack Query로 사용자에게 어떤 서비스를 제공하고자 하는지\n\n우리가 추구해야 하는 것은 기술적 고점이 아니다. 그렇기 때문에 이 라이브러리를 도입해서 사용자에게 어떤 경험을 선사할 수 있을지 고민하였다.\n\n1. Suspense\n    - Suspense는 사용자에게 '지금 무슨 일을 하는 중이다'라는 암시를 준다. 따라서 사용자의 기다리는 시간을 편하게 할 수 있다.\n    - 피움 서비스의 '식물 사전' 기능은 공공데이터를 활용한다. 현재 사용하고 있는 공공데이터의 경우 이용에 제약이 없어서 DB에 저장할 수 있다. 만약 그렇지 않아서 항상 백엔드 서버에서 공공데이터 API와의 통신을 추가적으로 진행해야 할 경우 정보를 받아오는 데 시간이 걸린다. 이 때 Suspense를 잘 활용할 수 있을 것이다.\n2. Refetch\n    - 피움 서비스는 모바일 환경을 우선적으로 고려하고 있다.\n    - 지하철 와이파이처럼 인터넷이 불안정한 곳에서는 요청이 잘 가지 않을 수 있다. 이 때 사용자가 같은 행동을 두 번 하지 않더라도 tanstack query가 자동적으로 요청을 보내서 UX 측면의 개선이 가능하다.\n3. caching\n    - '식물 사전 정보'는 변하지 않는 자료이다. 따라서 사용자가 여러 번 요청을 하더라도 매번 같은 정보를 보게 된다. 이러한 요청에 대해서는 `staletime`을 길게 잡아 캐시를 오래 유지한다면 불필요한 서버와의 통신을 줄이고 사용자 경험도 개선할 수 있다.\n    - '내가 키우는 식물 목록'이나 '내가 키우는 식물의 상세 정보'도 사용자가 값을 추가하거나 바꾸지 않는 이상 변하지 않는 값이다. 이 친구들도 적절한 캐싱을 사용하면 서버와의 통신을 줄여 사용자의 대기시간을 줄일 수 있다.\n4. 무한 스크롤\n    - 피움에서는 자신의 식물에게 물을 준 날짜들을 기억해서 타임라인 형태로 볼 수 있도록 제공할 계획이다. 타임라인은 시간의 흐름을 나타내기 위한 도구이다. '시간'과 '흐름' 모두 연속성을 띠는 표현인 만큼 무한 스크롤을 이용해 유의미한 경험을 제공할 것이다.\n\n\n### Tanstack Query v5를 사용하게 된 이유\n\n마지막으로 피움 프론트엔드에서 Tanstack query의 다섯 번째 메이저 버전을 사용하기로 한 이유를 짧게 남긴다. Tanstack query v5는 [획기적인 변화](https://tanstack.com/query/v5/docs/react/guides/migrating-to-v5)가 있고, alpha 단계이다.\n\n1. 어차피 버전은 5로 흘러간다. 피움 프론트엔드의 세 크루 모두 Tanstack query를 처음 배우는 단계라면 굳이 역사의 뒤안길로 흘러갈 v4부터 배울 필요는 없다고 생각한다.\n2. 문서를 살펴본 결과 v5의 '획기적인 변화'는 대부분 기존의 불필요하거나 문제를 일으키기 쉬운 기능을 제거하는 것이었다. 따라서 만약 v4를 학습해야 한다면 기존의 v5 공부 내용에서 덧붙이는 방법으로 가능할 것이다.\n3. 현재 피움 서비스에서는 복잡한 서버와의 데이터 통신은 없을 것 같다. 따라서 alpha 단계이기 때문에 무언가가 안 되는 상황은 없을 것으로 예상된다.\n"},{"excerpt":"이 글은 우테코 피움팀 크루 '주노'가 작성했습니다. 서론  http://pium.life 로 접속하면 피움의 홈페이지가 나오기까지의 과정을 기록으로 남겨보려고 한다. 본 과정은 서버 구축을 처음 하면서 과정을 이해하기위해 작성된 글입니다. 빠르게 따라할 수 있는 설정 기반 글을 원한다면 마지막 목차인 정리를 확인해보시길 바랍니다. 본 과정에서는 소량의 …","fields":{"slug":"/pium-deploy-step/"},"frontmatter":{"date":"July 18, 2023","title":"피움의 배포과정","tags":["배포","인프라"]},"rawMarkdownBody":"\n> 이 글은 우테코 피움팀 크루 '[주노](https://github.com/Choi-JJunho)'가 작성했습니다.\n \n\n## 서론\n\n![](.index_images/3162b98e.png)\n\nhttp://pium.life 로 접속하면 피움의 홈페이지가 나오기까지의 과정을 기록으로 남겨보려고 한다.\n\n> 본 과정은 서버 구축을 처음 하면서 과정을 이해하기위해 작성된 글입니다.\n> \n> 빠르게 따라할 수 있는 설정 기반 글을 원한다면 마지막 목차인 정리를 확인해보시길 바랍니다.\n\n> 본 과정에서는 소량의 과금(?)이 존재합니다.\n> (도메인 구입비용 : 약 4000원)\n\n## 도메인 정하기\n\n![](.index_images/8e211be2.png)\n\n> 도메인을 구입하기 위해 도메인 호스팅 사이트 [가비아](https://www.gabia.com/)를 이용했다.\n\n`pium.com` `pium.co.kr` `pium.net` 등등.\n서비스의 이름으로 자주 사용하는 도메인을 생성하고싶었으나 이미 존재하거나 가격이 너무 비싸다는 문제가 있었다.\n\n적당한 가격에 서비스의 이름을 가진 도메인인 `pium.life`를 선택했다. (1년 4000원)\n\n## 도메인 설정하기\n\n> 가비아 서비스를 기준으로 과정이 진행됩니다.\n\n`3.123.123.123`과 같은 인스턴스 public ip 주소를 `pium.life`로 별칭을 지정해주자.\n\n![](.index_images/ce5d100b.png)\n\n우측 상단의 `My 가비아` 탭으로 들어간다.\n\n![](.index_images/48a0d2d6.png)\n\n우측의 `DNS 관리툴` 탭으로 들어간다.\n\n![](.index_images/dbaa42b0.png)\n\n도메인의 `설정` 탭으로 들어간다.\n\n![](.index_images/0b4d4be0.png)\n\nDNS 관리 탭의 `설정` 혹은 `레코드 수정`에 들어간다.\n\n![](.index_images/d830ba27.png)\n\n위와 같이 레코드를 추가하고 저장한다.\n\n> CNAME 설정은 향후 서브도메인 설정을 위한 설정입니다.\n\n이제 http://pium.life 로 접속하면 서버로 바로 접속할 수 있게된다. (SSH 접속이 아닌 HTTP 접속을 의미한다.)\n\n## 환경 살펴보기\n\n피움은 하나의 EC2에 프론트엔드, 백엔드의 배포를 모두 진행하려고한다.\n\n이를 위해서라면 서로 다른 포트에 서비스를 띄워둔 뒤 각 요청별로 포트를 분산시킬 필요가 있다.\n\n![](.index_images/ee357fa5.png)\n\n때문에 위와 같은 흐름으로 요청이 진행되는 것이 최종 목표다!\n\n### EC2 보안규칙\n\n우아한테크코스 과정에서 제공되는 EC2의 보안규칙은 다음과 같다.\n\n- 사내에서만 22번 포트 접속 가능\n- 80, 443은 열려있음\n- 이외의 포트는 열려있지 않음.\n\n우리가 흔히 개발을 하면서 사용하는 3000번 포트 혹은 8080번 포트를 통해 해당 서버에 접근하지 못한다는 이야기다.\n\n즉, 다시말해 pium.life:8080과 같은 접근이 안된다는 이야기다.\n\n인바운드 규칙에서 8080 혹은 3000번 포트를 열어버리는 방법도 있겠지만 보안 규칙에 손대지 않으면서 해결할 수 있는 방법을 찾아보자.\n\n## nginx로 포트포워딩하기\n\nlinux에 존재하는 `iptables` 명령어를 통해 서버 자체적으로 포트포워딩 환경을 구성할 수도 있지만 현재 피움은 하나의 서버에서 두개의 어플리케이션을 배포하고 있고, 도메인도 하나다.\n\n따라서 후에 설명할 서브도메인을 적용하기 위해서라도 nginx를 이용하기로 한다.\n\n### nginx 설치하기\n\n```shell\nsudo apt install nginx\n```\n\n```shell\nsystemctl status nginx\n```\n\n![](.index_images/28e0139a.png)\n\n이제 주소창에 인스턴스 ip 를 치고 접속하면 다음과 같이 nginx default 페이지를 볼 수 있다. \n\n![](.index_images/9345764b.png)\n\n### 80 포트 접속을 8080 포트로\n\n> 해당 과정은 8080포트에 애플리케이션이 구동중인 상태에서 진행됩니다. \n> 다음 명령어로 8080포트에서 애플리케이션이 구동중인지 확인한다.\n>\n> ```shell\n> lsof -i tcp:8080\n> ```\n> ![](.index_images/1573063d.png)\n\n이제 nginx 설정파일을 작성하여 80포트로 오는 요청을 8080포트로 전환시켜본다.\n\n```shell\ncd /etc/nginx/sites-available/\n\nsudo vi default\n```\n\n> 주석처리 되어있는 부분은 제외하고 코드로 표현합니다.\n\n```shell\n# 변경 전 파일내용\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n        root /var/www/html;\n\n        index index.html index.htm index.nginx-debian.html;\n\n        server_name _;\n\n        location / {\n                try_files $uri $uri/ =404;\n        }\n}\n```\n\n처음 파일을 열어보면 위와같이 설정되어있을 것이다.\n\n최대한 간략하게 포트를 변경한다는 목적만 달성해보기 위해 다음 내용들을 수정해보자.\n\n- `root /var/www/html;` 주석처리\n- `index index.html index.htm index.nginx-debian.html;` 주석처리\n- `location / { ... }` 내부 내용에 다음 내용 추가\n  - `proxy_set_header Host $host:$server_port;`\n  - `proxy_set_header X-Real-IP $remote_addr;`\n  - `proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;`\n  - `proxy_pass http://127.0.0.1:8080;`\n\n```shell\n# 변경된 파일내용\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n        # root /var/www/html;\n\n        # index index.html index.htm index.nginx-debian.html;\n\n        server_name _;\n\n        location / {\n                proxy_set_header Host $host:$server_port;\n                proxy_set_header X-Real-IP $remote_addr;\n                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n                proxy_pass http://127.0.0.1:8080;\n        }\n}\n```\n\n위와같이 설정파일을 수정했다면 다음 명령어를 수행해 nginx를 다시 시작한다.\n\n```shell\nsudo systemctl restart nginx\n```\n\n![](.index_images/232c6d5d.png)\n\n스프링부트 애플리케이션을 실행중이였다면 위와같은 Whitelabel Error Page를 확인할 수 있을것이다.\n\n## 서브도메인 구성하기\n\n이제 80포트에서 8080포트로 요청을 변환하는 과정은 성공했다.\n\n하나의 서버에 프론트엔드, 백엔드 코드가 같이 띄워져야하므로 서브도메인을 통해 페이지와 API를 구분해줘야한다.\n\n### index 파일 지정하기 - default 파일 수정\n\n프론트에서 빌드 산출물로 나온 index.html을 기본 페이지로 참고하도록 설정하자.\n\n```shell\ncd /etc/nginx/sites-available/\n\nsudo vi default\n```\n\n```shell\n# 변경 전 설정내용\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n        # root /var/www/html;\n\n        # index index.html index.htm index.nginx-debian.html;\n\n        server_name _;\n\n        location / {\n                proxy_set_header Host $host:$server_port;\n                proxy_set_header X-Real-IP $remote_addr;\n                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n                proxy_pass http://127.0.0.1:8080;\n        }\n}\n```\n\n기존에 80포트를 8080포트로 포워딩시켜주는 설정을 바꿔준다.\n\n```shell\n# 변경 후 설정내용\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n        root /var/www/html;\n\n        index index.html;\n\n        server_name pium.life;\n\n        location / {\n        }\n}\n```\n\n이제 pium.life로 접속하면 `/var/www/html` 경로에 있는 `index.html`을 참조하도록 설정되었다.\n\n위 설정에 따르면 `index.html` 및 `bundle.js`, `assets` 등의 프론트 리소스들은 서버의 `/var/www/html`를 기준으로 위치시키면 된다.\n\n> 빌드 산출물 및 CD와 관련된 내용은 본 게시글에서 다루지 않습니다.\n\n### API 서버 지정하기 - api_config 파일 만들기\n\nhttp://api.pium.life 로 API를 호출하도록 구성해보자.\n\nnginx는 기본적으로 `/etc/nginx/sites-enabled` 경로에 있는 파일들을 참고하여 설정파일에 적용한다.\n\n> `/etc/nginx/nginx.conf` 파일의 60번째 줄 참고\n> \n> ![](.index_images/f4ceb33e.png)\n\n다음 과정을 통해 서브도메인 설정을 해보자.\n\n```shell\ncd /etc/nginx/sites-available\n\nsudo vi api_config\n```\n\n```shell\n# api_config 파일 내용\nserver {\n        listen 80;\n        listen [::]:80;\n\n        server_name api.pium.life;\n        \n        location / {\n                proxy_set_header Host $host:$server_port;\n                proxy_set_header X-Real-IP $remote_addr;\n                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n                proxy_pass http://127.0.0.1:8080;\n        }\n}\n```\n\n`server_name` 옵션을 통해 api.pium.life 라는 도메인으로 접근하는 요청을 확인하고, 맞다면 8080 포트로 변경한다.\n\n위와 같이 파일을 작성했으면 `sites-enabled` 경로에 soft link(바로가기)를 생성한다.\n\n```shell\nln -s /etc/nginx/sites-available/api_config /etc/nginx/sites-enabled/api_config\n```\n\n이제 nginx를 재시작하여 설정을 적용해보자.\n\n> 💡 Tip : `nginx -t` 명령어를 통해 현재 설정파일이 정상적으로 작성되었는지 확인할 수있다.\n> \n> ![](.index_images/10d7627b.png)\n\n![](.index_images/04601361.png)\n\nhttp://api.pium.life 로 접속하면 API로 연결되는것을 확인할 수 있다.\n\n## 정리\n\n- 8080 포트에 API 애플리케이션을 실행한다.\n- 도메인 구입 및 A 레코드, CNAME을 설정한다.\n- nginx를 설치한다.\n- 프론트 빌드 산출물을 `/var/www/html` 경로에 준비한다. (index.html, bundle.js, assets 등)\n- 서브도메인 및 포트포워딩 설정한다.\n\n### nginx 설정 명령어 따라가기\n\n```shell\n# nginx 설치\nsudo apt install nginx\n\n# default 파일 수정\nsudo vi /etc/nginx/sites-available/default\n```\n\n```shell\n# /etc/nginx/sites-available/default 파일 내용\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n        root /var/www/html;\n\n        index index.html;\n\n        server_name pium.life;\n\n        location / {\n        }\n}\n```\n\n```shell\n# api_config 파일 작성\nsudo vi /etc/nginx/sites-available/api_config\n```\n\n```shell\n# api_config 파일 내용\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n        root /var/www/html;\n\n        index index.html;\n\n        server_name pium.life;\n\n        location / {\n        }\n}\n```\n\n```shell\n# nginx 재시작 및 설정적용\nsudo systemctl restart nginx\n```\n\n## Reference\n\nhttps://jminie.tistory.com/110\n\nhttps://customer.gabia.com/manual/domain/287/1201"},{"excerpt":"이 글은 우테코 피움팀 크루 '주노'가 작성했습니다. 서론 피움팀에서 Jenkins를 도입하고 적용하는 과정을 거쳤다. 정확한 동작과정을 몰랐기 때문에 헤매는 상황이 빈번하게 있었다.\n이에 Jenkins를 설치하고 환경설정을 빌드서버 환경을 구축한 일련의 과정을 기록해두려고한다. 작업 환경 : Ubuntu 22.04.2 LTS 공식문서 살펴보기 젠킨스 공…","fields":{"slug":"/jenkins-setting/"},"frontmatter":{"date":"July 16, 2023","title":"젠킨스 설치하기","tags":["CI/CD","젠킨스","설정"]},"rawMarkdownBody":"\n> 이 글은 우테코 피움팀 크루 '[주노](https://github.com/Choi-JJunho)'가 작성했습니다.\n \n\n## 서론\n\n피움팀에서 Jenkins를 도입하고 적용하는 과정을 거쳤다.\n\n정확한 동작과정을 몰랐기 때문에 헤매는 상황이 빈번하게 있었다.\n이에 Jenkins를 설치하고 환경설정을 빌드서버 환경을 구축한 일련의 과정을 기록해두려고한다.\n\n> 작업 환경 : Ubuntu 22.04.2 LTS\n\n## 공식문서 살펴보기\n\n[젠킨스 공식문서](https://www.jenkins.io/doc/book/installing/linux/)를 확인하면 설치 방법이 친절하게 나와있다.\n\n아무것도 없는 EC2 환경에서 Jenkins를 설치하고 구동하는 과정을 따라가보자.\n\n## (Optional) Swap 메모리 설정하기\n\n프리티어환경에서 Jenkins를 사용하면 자칫 메모리가 부족한 상황이 발생할 수도 있다.\n2GB의 메모리는 젠킨스와 빌드를 모두 견디기 어려울 수도 있다.\n\n다음 명령어를 통해 서버에 Swap 메모리를 할당하자.\n\n```shell\nsudo fallocate -l 2G /swapfile\nsudo chmod 600 /swapfile\nsudo mkswap /swapfile\nsudo swapon /swapfile\n\nfree -h # 확인명령어\n```\n\n> [Swap 메모리 할당하기](https://velog.io/@junho5336/Swap-%EB%A9%94%EB%AA%A8%EB%A6%AC-%ED%95%A0%EB%8B%B9%ED%95%98%EA%B8%B0)를 참고\n\n## java 설치하기\n\n> 설치 방법은 [공식문서](https://www.jenkins.io/doc/book/installing/linux/)를 확인하면서 진행하고있습니다.\n\n현재 사용할 jenkins의 버전은 java 17을 사용한다.\njava 17버전을 설치하자\n\n```shell\nsudo apt update\nsudo apt install openjdk-17-jre\njava -version\n```\n\n![](.index_images/93d56503.png)\n\n## jenkins 설치하기\n\n다음 명령어를 수행하여 jenkins를 설치한다.\n\n```shell\ncurl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key | sudo tee \\\n  /usr/share/keyrings/jenkins-keyring.asc > /dev/null\necho deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \\\n  https://pkg.jenkins.io/debian-stable binary/ | sudo tee \\\n  /etc/apt/sources.list.d/jenkins.list > /dev/null\nsudo apt-get update\nsudo apt-get install jenkins\n\nsudo systemctl status jenkins # 실행상태 확인\n```\n\n![](.index_images/99b45540.png)\n\n\n## jenkins 접속하기 & 초기설정\n\n> jenkins는 기본적으로 8080포트를 사용한다.\n> jenkins의 포트를 변경하는 방법에 대해서는 본 글에서 다루지는 않는다.\n\n`{인스턴스-public-ip}:8080` 으로 접속하면 다음과 같은 화면을 볼 수 있다.\n\n![](.index_images/4492665d.png)\n\n다시 EC2 화면으로 넘어와서 다음 명령어를 수행하여 `initialAdminPassword`를 알 수 있다.\n\n```shell\nsudo cat /var/lib/jenkins/secrets/initialAdminPassword\n```\n\n![](.index_images/f55b94c9.png)\n\n확인한 암호를 화면에 입력한 뒤 Continue 버튼을 눌러 계속 진행한다.\n\n![](.index_images/28fea7e9.png)\n\n초기 플러그인 세팅 화면이 나오는데 `Install suggested plugins` 를 눌러 초기 플러그인 설정을 진행한다. \n\n![](.index_images/c78a9517.png)\n\n![](.index_images/82bae04f.png)\n\n초기 Admin 유저를 생성할 수 있다.\n\n![](.index_images/a8f14e43.png)\n\njenkins의 기본 URL을 설정할 수 있다. 기본값을 권장한다. \n\n![](.index_images/84efb2c8.png)\n\n여기까지 했으면 초기 설정은 완료했다고 볼 수 있다.\n\n만약 위 과정에서 admin 유저를 생성하지 않았다면 `admin` 이라는 기본 유저로 로그인 할 수 있다고 설명하고 있다.\n비밀번호는 `initialAdminPassword` 과정에서 입력했던 값으로 설정되어있다.\n\n![](.index_images/60ba97ad.png)\n\n이렇게 Jenkins를 설치할 수 있다.\n\n## Reference\n\nhttps://www.jenkins.io/doc/book/installing/linux/\n"},{"excerpt":"이 글은 우테코 피움팀 크루 '그레이'가 작성했습니다. 서론 JPA를 이용해 엔티티를 설계하다가  어노테이션과 @Column의 의 차이점이 궁금해져 알아보았습니다. nullable = false ?? JPA는 엔티티를 매핑하고 설계하면 자동으로 DDL을 생성해 주는 기능을 제공합니다. \n또한 엔티티의 각 컬럼들에 대해 NOT NULL, UNIQUE 등과 …","fields":{"slug":"/jpa-notnull-nullable/"},"frontmatter":{"date":"July 16, 2023","title":"@NotNull과 nullable = false는 어떤 차이가 있을까?","tags":["JPA","Validation","nullable"]},"rawMarkdownBody":"\n> 이 글은 우테코 피움팀 크루 '[그레이](https://github.com/Kim0914)'가 작성했습니다.\n\n\n## 서론\n\nJPA를 이용해 엔티티를 설계하다가 `@NotNull` 어노테이션과 @Column의 `nullable=false`의 차이점이 궁금해져 알아보았습니다.\n\n\n## nullable = false ??\n\nJPA는 엔티티를 매핑하고 설계하면 자동으로 DDL을 생성해 주는 기능을 제공합니다. \n또한 엔티티의 각 컬럼들에 대해 NOT NULL, UNIQUE 등과 같은 제약 조건이 포함되는 경우에도 자동으로 DDL을 생성해 줍니다.\n\n\n\n엔티티를 설계할 때 일반적으로 @Column 어노테이션을 활용합니다. \n@Column 어노테이션에서 해당 컬럼의 NOT NULL 제약을 설정할 수 있는데 `@Column(name = \"email\", nullable = false)`와 같이 nullable=false 설정을 걸어주면, 해당 제약 조건을 명시할 수 있습니다. \n따로 명시하지 않으면 nullable의 기본 값은 true입니다.\n\n\n\n간단한 User 엔티티를 생성해 보겠습니다.\n\n```java\n@Entity\n@Table(name = \"user\")\npublic class User extends AuditingEntity {\n\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    @Column(name = \"id\", updatable = false)\n    private Long id;\n\n    @Column(name = \"user_id\", length = 20)\n    private String userId;\n\n    @Column(name = \"password\", length = 20)\n    private String password;\n\n    @Column(name = \"name\", length = 20)\n    private String name;\n\n    @Column(name = \"email\", nullable = false, length = 50)\n    private String email;\n}\n```\n\nUser 테이블의 email 필드는 반드시 값이 존재해야 합니다. \n즉, **NOT NULL 제약 조건이 필요**합니다. \n여기서 JPA가 자동으로 생성하는 DDL을 확인해 보겠습니다.\n\n![](./.index_images/img.png)\n\n`email varchar(50) not null` 과 같이 not null 제약 조건이 자동으로 명시됨을 알 수 있습니다.\n\n\n\n하지만 DDL은 애플리케이션 내부가 아닌 데이터베이스 컬럼의 속성에 대한 조건이므로, 스프링(자바) 애플리케이션 내 User 엔티티의 email 필드는 null이 허용됩니다.\n\n\n\n테스트 코드로 확인해 보겠습니다.\n\n```java\n@TestConstructor(autowireMode = TestConstructor.AutowireMode.ALL)\n@DataJpaTest\nclass UserRepositoryTest {\n\n    private final UserRepository userRepository;\n\n    public UserRepositoryTest(UserRepository userRepository) {\n        this.userRepository = userRepository;\n    }\n\n    @Test\n    void save() {\n        User user = new User(\"gray1234\", \"password\", \"gray\", null);\n\n        User savedUser = userRepository.save(user);\n\n        assertThat(savedUser).isEqualTo(user);\n    }\n}\n```\n\n![](./.index_images/img2.png)\n\n테스트가 실패함을 확인할 수 있습니다.\n\n\n\n하지만 여기서 주의 깊게 살펴볼 점이 있습니다. 예외 메시지를 따라 올라가 보면 insert 쿼리가 한 번 발생한 것을 알 수 있습니다. 또한 발생한 예외 타입이 JdbcSQL.... Exception입니다.\n\n\n\n즉 애플리케이션 내부가 아닌, 데이터베이스 내에서 예외가 발생했다는 것입니다.\n\n![](./.index_images/img3.png)\n\n애플리케이션 내에서는 email 컬럼의 null을 체크하지 못하고, 데이터베이스에 쿼리가 실행될 때 예외가 발생한다는 것입니다. 또한 insert 쿼리가 데이베이스에서 실행되므로 Auto Increment인 PK가 증가합니다.\n\n![](./.index_images/img4.png)\n\n첫 번째 유저를 저장할 때는 email 값을 null로 할당한 후 try - catch를 이용해 예외를 삼키고, 두 번째 유저는 정상적으로 저장한 후 PK를 출력해 봤습니다. 예상한 것처럼, 두 번째 유저의 PK는 2 임을 확인할 수 있습니다.\n\n\n\n**그렇다면, 애플리케이션 내 엔티티에서는 null을 어떻게 막을 수 있을까요?**\n\n\n## @NotNull과 함께라면?\n\n`@NotNull`은 java validation에 속하며 `@Valid`를 이용한 요청을 처리하는 단계에서 예외를 잡을 수도 있고, bean validation을 통해 예외를 검증할 수도 있습니다.\n\n\n\n우리가 DTO와 같이 클래스의 필드를 검증하는 방법과 동일하게 엔티티의 필드도 검증할 수 있습니다. 당연히 같은 자바 객체이고 도메인이기 때문에 동일하게 적용할 수 있습니다.\n\n\n\n@Valid 어노테이션도 없이 어떻게?라고 생각할 수 있는데요, Hibernate는 엔티티에 적용된 Bean Validation 어노테이션 역시 DDL로 변환합니다. \n@NotNull은 nullable=false와 마찬가지로 DDL 상에서 해당 컬럼이 NOT NULL 제약조건을 가짐을 명시합니다.\n\n\n\n스프링 공식문서인 밸덩에서도 이를 명확히 언급하고 있습니다. [밸덩 바로가기](https://www.baeldung.com/hibernate-notnull-vs-nullable)\n\n\n\n이전 User 테이블에 nullable=false를 제거한 후 @NotNull 어노테이션만 붙여준 후 생성되는 DDL을 살펴보겠습니다.\n\n```java\n@Entity\n@Table(name = \"user\")\npublic class User extends AuditingEntity {\n\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    @Column(name = \"id\", updatable = false)\n    private Long id;\n\n    @Column(name = \"user_id\", length = 20)\n    private String userId;\n\n    @Column(name = \"password\", length = 20)\n    private String password;\n\n    @Column(name = \"name\", length = 20)\n    private String name;\n\n    @NotNull\n    @Column(name = \"email\", length = 50)\n    private String email;\n}\n```\n\n![](./.index_images/img5.png)\n\n동일하게 **email varchar(50) not null** 과 같이 not null 제약 조건이 자동으로 명시됨을 알 수 있습니다.\n\nHibernate에 의해 DDL이 자동으로 생성되는 기능을 끄고 싶다면 아래와 같이 설정하면 됩니다.\n\n```properties\nspring.jpa.properties.hibernate.validator.apply_to_ddl=false\n```\n\n그렇다면 nullable = false와 어떤 차이가 있을까요?\n\n차이점을 알아보기 위해 이전에 User의 email 필드에 null을 세팅한 후 저장하는 테스트 코드를 실행해보겠습니다.\n\n![](./.index_images/img6.png)\n\n다음과 같이 `javax.validation.ConstraintViolationException` 예외가 발생한다는 것을 알 수 있습니다. 또한 nullable=false 방식 때 발생하던 **insert 쿼리가 발생하지 않는다**는 점도 함께 볼 수 있습니다.\n\n\n\n`javax.validation.ConstraintViolationException` 예외가 발생했다는 것은 스프링(자바) 애플리케이션 내에서 예외를 잡았다는 것입니다. 그러므로 데이터베이스에 쿼리가 실행될 일이 없습니다.\n\n\n\n좀 더 정확하게 말하면 객체가 생성되는 시점이 아닌 **엔티티가 영속화되는 시점에 예외가 발생**합니다.\n\n\n\n확실하게 알아보기 위해 동일한 User1, User2 저장 테스트를 실행해 보면 2번째로 저장한 유저의 PK가 1 임을 알 수 있습니다.\n\n![](./.index_images/img7.png)\n\n또한 @NotNull을 어노테이션을 사용하게 되면 예외 메시지를 직접 작성할 수 있는 장점도 존재합니다.\n\n---\n\n여담으로, @NotNull 없이 nullable=false 만 설정한 경우에도 NULL 검증을 진행하고 싶다면 아래와 같이 설정하면 됩니다.\n```properties\nspring.jpa.properties.hibernate.check_nullability=true\n```\n![](./.index_images/img8.png)\n\n\b스프링(자바) 애플리케이션 단에서 예외가 잡히는 것을 볼 수 있습니다. 하지만 예외 타입이 hibernate.PropertyValueException으로 다릅니다.\n\n\n\n굳이 추천하는 방법은 아닌 것 같습니다.\n\n\n\n또한 `@NotBlank`나 `@NotEmpty`는 자동으로 DDL을 생성해주지 않습니다.\n\n그러므로 @NotBlank나 @NotEmpty를 사용하는 경우에는 `@Column(nullable=false)`를 반드시 추가해야 DDL에 NOT NULL 제약조건이 반영됩니다.\n\n---\n\n## 정리\n**@Column(nullable = false)**\nDDL을 자동으로 생성하지만, 애플리케이션의 영속성 컨텍스트에서 엔티티 필드에 null이 들어가는 것을 막지 못한다.\n\n또한 데이터베이스에 쿼리가 실행된 후 예외가 발생한다.\n\n\n\n**@NotNull**\nDDL을 자동으로 생성하고 애플리케이션의 영속성 컨텍스트에서 엔티티 필드에 null이 들어가는 것을 막는다.\n\n잘못된 제약 조건인 경우 데이터베이스에 불필요한 쿼리를 날리지 않는다.\n\n추가적으로 Bean Validation 방식은 예외 메세지를 직접 작성할 수 있다.\n\n또한 @Size와 같이 다른 validation을 통해 엔티티 필드 값을 검증할 수 있다.\n\n\n단점으로는 코드가 지저분해지고, JPA를 이용한 엔티티화 시킨 것이 아닌 객체라면 @NotNull 어노테이션을 해석하지 못한다.\n\n\n하이버네이트에서는 nullable=false보다 @NotNull 사용을 조금 더 권장하고 있다.\n\n\n## 레퍼런스\nhttps://www.baeldung.com/hibernate-notnull-vs-nullable\n\nhttps://kafcamus.tistory.com/15\n\n"},{"excerpt":"이 글은 우테코 피움팀 크루 '주노'가 작성했습니다. 서론 피움팀의 기술블로그를 만들기까지의 험난한 과정을 정리해보려고 한다. 플랫폼 선정 팀 블로그를 작성하기 위해 다양한 플랫폼들을 고려해봤다. 티스토리 티스토리는 팀 블로그 기능을 통해 다양한 작성자 및 관리자를 지정할 수 있다. 하지만 UI를 직접 수정할 수 없을 뿐더러 제공되어있는 스킨들이 대부분 …","fields":{"slug":"/blog-starter/"},"frontmatter":{"date":"July 09, 2023","title":"피움 블로그 생성과정","tags":["블로그","세팅"]},"rawMarkdownBody":"\n> 이 글은 우테코 피움팀 크루 '[주노](https://github.com/Choi-JJunho)'가 작성했습니다.\n \n\n## 서론\n\n피움팀의 기술블로그를 만들기까지의 험난한 과정을 정리해보려고 한다.\n\n## 플랫폼 선정\n\n팀 블로그를 작성하기 위해 다양한 플랫폼들을 고려해봤다.\n\n### 티스토리\n\n티스토리는 팀 블로그 기능을 통해 다양한 작성자 및 관리자를 지정할 수 있다.\n\n하지만 UI를 직접 수정할 수 없을 뿐더러 제공되어있는 스킨들이 대부분 마음에 들지 않았다.\n\nUI 선정과정에 너무많은 힘을 들일 것 같아서 티스토리는 사용하지 않았다.\n\n### Notion\n\n현재 팀 문서 정리를 Notion으로 관리하고있다.\n\n자유롭게 템플릿을 관리할 수 있어서 가장 매력적으로 다가온 툴이였지만 SEO를 적용하지 못하고, 도메인을 별도로 지정해야한다는 단점이 있어 선택하지 않았다.\n\n> 중간에 vercel에서 제공하는 notion 배포기능을 사용하는 방식이 있었지만 Organizaiton으로 레포지토리를 관리하고 있는 현재 상황에서 해당 서비스를 이용하려면 유료였기 때문에 해당 부분도 사용하지 못했다.\n[Notion-backed Next.js Blog](https://vercel.com/templates/next.js/notion-blog)\n\n\n### Velog\n\n팀 계정을 생성해서 Velog에 글을 게시하는 방법을 생각해봤다.\n\n팀 계정을 생성한다는 부분에서 팀 프로젝트가 계속 진행되면서 계정을 관리하는 리소스가 추가되는것이 우려되었기 때문에 선택하지 않았다.\n\n\n### GitBook\n\nGitBook을 이용해서 팀 블로그를 운영할 수도 있겠지만 UI 구성적인 측면에서 기술블로그와는 거리가 멀었기 때문에 선택하지 않았다.\n\n\n### GitHub Pages\n\n정적인 페이지를 무료로 호스팅할 수 있고, 마음만 먹으면 자유롭게 커스터마이징 할 수 있는 환경이라는 부분이 매력있게 다가와 GitHub Pages를 선택했다.\n\n## GitHub Pages로 팀 블로그 만들기\n\n이제 본격적으로 GitHub Pages를 이용하여 팀 블로그를 만드는 과정을 차근차근 따라가보자.\n\ngatsby를 이용하여 블로그 배포를 진행했다. 사용한 템플릿은 gatsby-starter-hoodie이며 블로그에 친절하게 사용법이 게시되어있다.\n\n[🐙 gatsby-starter-hoodie](https://github.com/devHudi/gatsby-starter-hoodie)\n[🚀 gatsby-starter-hoodie 사용 방법 보러가기](https://hoodie.gatsbyjs.io/about-hoodie-kr/)\n\n> 필자는 gatsby에 대해 아무것도 모르는 상태로 해당 작업을 진행했습니다. 😵‍💫\n최대한 알기 쉽게 정리하려고 노력했습니다만... 잘못된 부분이 있다면 댓글로 남겨주시면 감사하겠습니다.\n\n### gatsby란?\n\n우선 사용하고자하는 gatsby가 무엇인지부터 알고 진행해보자.\n\n[위키백과](https://en.wikipedia.org/wiki/Gatsby_(JavaScript_framework))에 따르면\n\n**개츠비는 React와 GraphQL을 사용하여 Node.js 위에 구축된 오픈소스 정적 사이트 생성기입니다.**\n\n라고 설명되어있다.\n\n`Node.js 위에 구축된` 해당 문구로부터 로컬 환경에 Node.js가 필요하다는 것을 알 수 있다.\n\n### node 설치하기\n\n```shell\nbrew install node\n```\n\n![](.index_images/dd266184.png)\n\n`node -v` 명령어를 통해 잘 설치되었는지 확인해본다.\n\n### npx 설치하기\n\n리액트를 공부하자는 글이 아니기 때문에 간단히만 알고 넘어가자\n\nnpx는 npm 사용시에 발생하는 발생할 수 있는 여러 문제점을 해결하기 위해 설계되었다고한다.\n진행하는 과정에서 npx를 사용할 것이기 때문에 npx도 설치하고 넘어가자.\n\n```shell\nnpm install npx -g\n```\n\n![](.index_images/ff1c3736.png)\n\n`npx -v` 명령어를 통해 잘 설치되었는지 확인해본다.\n\n### gatsby-cli 설치하기\n\ngatsby 명령어를 사용하기 위해 gatsby-cli를 설치한다.\n\n```shell\nnpm install -g gatsby-cli\n```\n\n![](.index_images/6494ac93.png)\n\n`gatsby -v` 명령어를 통해 잘 설치되었는지 확인해본다.\n\n### Gatsby 사이트 생성\n\n> 여기서부터는 [Hudi의 Gatsby 환경 구성하기](https://hoodie.gatsbyjs.io/quick-start-kr/)를 따라가는 내용입니다.\n\n> 환경은 Pium의 프로젝트 환경에 맞게 진행됩니다.\n\ngatsby를 이용하여 새로운 사이트를 생성한다.\n이때 `gatsby-starter-hoodie`를 참고하여 구성한다.\n\n```node\nnpx gatsby new pium-official.github.io https://github.com/devHudi/gatsby-starter-hoodie\n```\n\n### 프로젝트 시작해보기\n\n``` shell\ncd pium-official.github.io\n\nnpm run start\n```\n\n![](.index_images/19f5a8e2.png)\n\n`localhost:8000`으로 프로젝트가 열리는 모습을 볼 수 있다.\n\n![](.index_images/7810b698.png)\n\n### 블로그 커스텀하기\n\n해당 부분은 원작자의 [🚀 2.빠르게 시작하기](https://hoodie.gatsbyjs.io/quick-start-kr/)를 참고하여 진행하면 된다.\n\n### GitHub Pages로 배포하기\n\n이제 배포할 페이지를 다 만들었다!\nGitHub Pages를 이용해 배포를 진행해보자.\n\n우선 GitHub Repository를 생성한다.\n\n> pium-official Organization에서 `pium-official.github.io` 레포지토리를 생성했다.\n\n![](.index_images/b084df05.png)\n\n```shell\ngit remote add origin https://github.com/pium-official/pium-official.github.io\n```\n\n```node\nnpm run deploy-gh\n```\n\n위 명령어를 수행하면 팀 레포지토리에 gh-pages 브랜치가 생성되고 build된 결과물이 올라온다. 해당 파일을 기준으로 GitHub Pages에서 배포를 진행한다.\n\n![](.index_images/3db58ec3.png)\n\n> GitHub Pages에서 배포 기준으로 잡는 브랜치를 확인 & 변경하고 싶다면 Settings - Pages 에서 다음 항목을 확인하면 된다.\n> ![](.index_images/b9a5c99c.png)\n\n![](.index_images/1877666d.png)\n\nGitHub Actions 탭에서 `pages build and deployment` 작업이 완료된것을 확인하고 https://pium-official.github.io/ 로 접속해보면 페이지가 성공적으로 배포된것을 확인할 수 있다!!\n\n> https:://{팀 레포명}.github.io\n\n![](.index_images/f35d015e.png)\n\n### 글 작성하기\n\n해당 템플릿에 글을 작성하는 방식은 원작자의 [🤔 3. 작성 가이드](https://hoodie.gatsbyjs.io/writing-guide-kr/)를 참고하면 된다.\n\n### GitHub Actions workflow\n\n현재까지 진행한 작업으로는 다음과 같은 흐름으로 배포를 진행할 수 있다.\n\n1. 로컬에서 글을 작성한다.\n2. 글을 작성한 뒤 `npm run deploy-gh` 명령어를 수행해서 배포를 진행한다.\n\n위 방식은 혼자서 작업할 때는 문제가 없으나 여러명이 함께 글을 작성하기에는 많이 번거롭다.\n\n우리는 다음과 같은 방식으로 배포를 하는 방향을 기대하고 있다.\n\n1. 로컬에서 글을 작성한다.\n2. 글을 작성한 뒤 main 브랜치로 push한다.\n3. main 브랜치에 작업내용이 push 되었을 때 빌드 및 배포가 자동적으로 이뤄진다.\n\n위에서 3번 작업내용을 수행하기 위해 GitHub Actions의 workflow 기능을 이용할 수 있다.\n\n### workflow 작성하기\n\n`gatsby-starter-hoodie`에서 기본적으로 제공하고 있는 workflow는 다음과 같이 구성되어있다.\n\n```yml\nname: CI\n\non:\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v2\n        with:\n          node-version: 20.3.1\n\n      - name: Install node packages\n        run: yarn\n        \n      - name: Check lint\n        run: yarn check:lint\n        \n      - name: Check prettier\n        run: yarn check:prettier\n      \n      - name: Build\n        run: yarn build\n```\n\n> 자세한 구문에 대한 설명 및 내용은 [공식문서](https://docs.github.com/ko/actions/using-workflows/workflow-syntax-for-github-actions)를 참고해보면 좋다.\n\n기존에 존재하는 ci.yml 파일은 삭제하고 아래와 같은 deploy.yml을 작성해보자.\n\n> workflow에 대한 yml파일의 경로는 반드시 `.github/workflows` 폴더 내부에 존재해야한다.\n> ![](.index_images/d9fc2f50.png)\n \n\n```yml\nname: Deploy\n\non: # 어떤 작업이 수행될 때 deploy.yml 작업이 수행된다. (트리거)\n  push: # push 작업이 수행될 때\n    branches: # 특정 브랜치를 대상으로\n      - main\n\npermissions: # github action이 수행되는 환경에서 특정 권한을 준다\n  contents: write\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v2\n        with:\n          node-version: 20.3.1\n\n      - name: Install node packages\n        run: yarn\n\n      - name: Build\n        run: yarn build\n\n      - name: Deploy 🚀\n        uses: JamesIves/github-pages-deploy-action@v4\n        with:\n          folder: public\n```\n\n> `JamesIves/github-pages-deploy-action@v4` 작업에서 수행하는 내용 중 쓰기권한을 요구하는 작업이 있기 때문에 permissions 설정을 해야한다.\n[관련 이슈 - Failed with exit code 128, Permission Denied](https://github.com/JamesIves/github-pages-deploy-action/issues/1110)\n\n위 deploy.yml 파일을 작성했다면 프로젝트 내부에서 변경사항에 대한 commit을 수행하고 git push를 해본다.\n\n``` shell\ngit branch -m main\n\ngit push origin main\n```\n\n![](.index_images/0491f96f.png)\n\n위 내용을 대략적으로 설명해보자면 다음과 같다.\n\nmain 브랜치에 대한 코드를 build해보고 성공한다면 결과물을 gh-pages 브랜치로 배포한다.\n\n이제 글을 작성하고 main 브랜치로 push하기만 하면 배포까지 자동으로 수행된다.\n로컬에서 `npm run deploy-gh`는 더이상 사용할 필요가 없다.\n\n## 결론\n\n블로그를 생성하고 배포하고 자동화하는 과정까지 차근차근 진행해봤다.\n\n여러버 삽질을 거친 끝에 완성했기 때문에 더 애정이 많이 가는 것 같다. 👍\n\n## Reference\n\nhttps://hoodie.gatsbyjs.io/\nhttps://docs.github.com/ko/actions/using-workflows/workflow-syntax-for-github-actions\nhttps://studium-anywhere.tistory.com/21\n"},{"excerpt":"이 글은 우테코 피움팀 크루 '주노'가 작성했습니다. 서론 기획부터 개발까지 하나의 프로그램이 생성되는 모든 프로세스를 경험할 수 있는 시간을 가졌다. 피움팀에서 어떤 방식을 통해 아이디어와 기능을 도출해나갔는지 기록해두고자 한다. 스프린트란? 스프린트는 팀이 일정량의 작업을 완료하는 시간이 정해진 짧은 기간을 의미한다. 여기서는 기획부터 데모수준의 프로…","fields":{"slug":"/sprint-idea/"},"frontmatter":{"date":"July 08, 2023","title":"구글 스프린트 기반 아이디어 도출","tags":["아이디어","기획"]},"rawMarkdownBody":"\n> 이 글은 우테코 피움팀 크루 '[주노](https://github.com/Choi-JJunho)'가 작성했습니다.\n\n## 서론\n\n기획부터 개발까지 하나의 프로그램이 생성되는 모든 프로세스를 경험할 수 있는 시간을 가졌다.\n\n피움팀에서 어떤 방식을 통해 아이디어와 기능을 도출해나갔는지 기록해두고자 한다.\n\n## 스프린트란?\n\n스프린트는 팀이 일정량의 작업을 완료하는 시간이 정해진 짧은 기간을 의미한다.\n\n여기서는 기획부터 데모수준의 프로그램이 나오는 단계까지를 하나의 스프린트라고 생각해볼 수 있겠다.\n\n피움 팀은 구글 스프린트의 방법론을 차용해서 기능을 도출했다.\n\n### 구글 스프린트\n\n![](.index_images/googlesprint.png)\n\n5일간 결과물을 도출하는 방법론으로 다음과 같은 17단계로 이어진다.\n\n1. 현재 상황에 대한 구성원들의 생각과 문제 상황 공유\n2. 스프린트를 통해 해결하고자 하는 목표 설정\n3. 스프린트 질문 도출\n4. 이해관계자의 구매 여정 Map 작성\n5. 전문가 조언\n6. HMW(어떻게 하면 ~할 수 있을까) 작성 및 선정\n7. 스프린트 기간에 주력하고자 하는 1순위 타깃과 질문 선정\n8. 번갯불 대화 및 솔루션 스케치\n9. 고객 선정을 위한 설문지 작성\n10. 프로토타입 제작을 위한 최종 솔루션 선정\n11. 프로토타입 제작을 위한 스토리보드 만들기\n12. 프로토타입 제작\n13. 프로토타입 완성 및 시연\n14. 고객 인터뷰용 질문 만들기 (인터뷰 담당자)\n15. 타깃 고객 인터뷰 및 학습\n16. 스프린트 이후의 개발 플랜 점검 및 향후 일정 논의\n17. 성찰\n\n### Figma - Figjam\n\n오프라인 환경에서 종이, 캔버스, 포스트잇을 이용해서 각자의 의견을 종합해볼 수도 있지만 시간, 공간적 제약이 있을 때는 Figma를 사용해볼 수도 있다.\n\n디자인 툴인 Figma에는 Figjam이라는 기능을 제공한다.\n\n![](.index_images/figjam.png)\n\nFigjam에서는 포스트잇, 연필그리기, 스티커붙이기, 타이머 등의 기능들을 제공한다.\n\n> 개인적으로 타이머 기능을 적극 활용하는 것이 좋다고 생각했다.\n위 [구글 스프린트](###구글-스프린트)의 `8. 번갯불 대화 및 솔루션 스케치` 항목에서 추구하는 목적이 무엇인지 생각해보면 정해진 시간내로 서로의 의견을 제시하여 회의가 늘어지지 않게 하기 위함임을 알 수 있다.\n정해야할 내용이 많은 만큼 시간이 늘어지는 것만큼은 가장 경계해야한다고 생각한다.\n\n## 서비스 주제\n\n![](.index_images/b95b5dfe.png)\n\n`식물을 잘 키울 수 있도록 도와주는 서비스`라는 주제로 팀이 이뤄졌다.\n\n위 포스터를 확인했을 때 큰 주제로 추상적인 목표들이 즐비해있음을 확인할 수 있다.\n주어진 시간이 짧기 때문에 핵심기능을 추려야할 필요가 있다.\n\n> 💡 모든 과정을 진행할 때 이야기를 듣는 사람들은 형광펜 혹은 스티커 기능을 이용해 중요하다고 생각하는 부분에 색칠을 하며 듣는다. 형광펜과 스티커를 이용한 호응을 이용해 공통 관심사에 집중할 수 있으며 집중력이 분산되는 것도 예방할 수 있다.\n\n> ⏰ 모든 과정에는 제한시간이 존재한다.\n제한시간을 두고 회의가 루즈해지는 것을 막아야만한다!!\n\n### 서비스의 목적과 가치\n\n![](.index_images/959281a8.png)\n\n서비스의 목적과 가치에 대해 구상한다.\n\n이 단계에서는 `서비스가 어떤 기능을 제공함으로서 어떤 문제를 해결한다`를 이야기하며 각자가 추상적인 목표를 어떤 방향으로 구체화하고 있는지 공유한다.\n\n> ⏰ 제한시간 : 3분\n\n### 서비스의 대상\n\n![](.index_images/db53c739.png)\n\n어떤 사용자가 이 서비스를 사용할 지 떠올리고 각자의 생각을 작성한다.\n\n이후 각자가 자신의 생각을 이야기하는 시간을 가진다.\n\n> ⏰ 제한시간 : 3분\n\n\n### 어떻게 하면 ~문제를 해결할 수 있을까?\n\n![](.index_images/1c560fdf.png)\n\n어떻게 하면 ~ 문제를 해결할 수 있을까? 라는 질문들을 작성하고 이야기한다.\n\n이 과정을 통해 해결해야할 문제들을 인지할 수 있다.\n\n이 때 기술적인 질문이 나오지 않도록 경계해야한다.\n해당 과정을 수행하는 이유는 서비스의 목적을 구체화하기 위함이다.\n\n- 어떻게 하면 제 시간에 식물에 물을 줄 수 있을까? (O)\n- 어떻게 하면 무중단 배포를 할 수 있을까? (X)\n\n> ⏰ 제한시간 : 5 ~ 8분\n\n### 워드 클라우드\n\n![](.index_images/07da0c75.png)\n\n위 단계에서 나온 키워드들을 기준으로 단어들을 나열한다.\n중요하게 생각되는 단어들은 크고 굵게 표기한다.\n\n이 과정을 통해 키워드를 간략하게 추릴 수 있다.\n\n> ⏰ 제한시간 : X\n\n### (선택) 모바일 vs 데스크탑\n\n![](.index_images/8f5a28d2.png)\n\n생각하는 서비스가 어떤 환경에서 운영될지 생각해본다.\n\n이 과정을 통해 서비스가 어떻게 그려질지 대략적으로 생각해볼 수 있다.\n\n> ⏰ 제한시간 : 2분\n\n### 장치/요소/기능 브레인스토밍\n\n![](.index_images/2d693ea9.png)\n\n앞서 설정한 문제, 키워드 등을 참고하여 개발하고자 하는 서비스에 있을 것 같은 기능들을 브레인 스토밍 식으로 작성한다.\n\n이 과정을 통해 서비스에 존재할 수 있는 기능들을 파악할 수 있다.\n\n> ⏰ 제한시간 : 5 ~ 8분\n\n### 지도 만들기\n\n![](.index_images/2bb017bc.png)\n\n앞서 정의한 서비스 대상을 참고하여 구체적인 페르소나를 지정한다.\n페르소나를 참고하여 어떤 페이지들이 존재할지 생각해본다.\n\n위(`장치/요소/기능 브레인스토밍`)에서 도출된 기능들을 기반으로 각 페이지에 기능들을 작성한다.\n\n이 과정을 통해 대략적인 서비스 흐름과 구성을 생각해 볼 수 있다.\n\n> ⏰ 제한시간 : X\n\n### 페이지 그려보기\n\n![](.index_images/efe27f26.png)\n\n위 `지도 만들기` 활동에서 도출된 페이지들을 직접 그려보는 시간을 가진다.\n팀원들 각자가 페이지가 어떻게 구성될지 대략적으로 그려본다.\n\n잘 그릴 필요는 없다. 연필로 어떤 버튼이 어디에 위치할지, 어떤 기능이 존재하는지 정도만 알아볼 수 있을정도로 가볍게 스케치해도 좋다.\n\n이 과정을 통해 각자가 생각하는 View를 공유하면서 서비스의 구현 방향성에 대한 싱크를 맞춰갈 수 있다.\n\n> ⏰ 제한시간 : 각 페이지별 5분\n\n### 결정권자 정하기 & 페이지 정하기\n\n![](.index_images/9f853c4e.png)\n\n위 과정에서 작성한 페이지 중 하나의 페이지를 결정하기 위해 결정권자를 정한다.\n\n결정권자는 팀원들의 투표로 정하고 페이지를 결정할 때 만큼은 결정권자의 권한이 가장 높은 수직적인 구조로 진행된다.\n즉, 다시말해 페이지는 결정권자의 선택으로 정해진다.\n\n결정권자를 뽑았다면 각 페이지를 정하는 시간을 가진다.\n\n이 때 결정권자가 아닌 다른 팀원들은 자신의 페이지 혹은 자신이 마음에 드는 페이지에 대해 결정권자를 설득한다.\n\n페이지를 결정 할 때 여러 페이지의 기능을 합칠 수도 있다.\n\n> ⏰ 제한시간 : 각 페이지별 5분 \n> 결정된 페이지들은 명예의전당👑 에 복사하여 올려둔다.\n> ![](.index_images/e4e8a0fb.png)\n\n\n### BDD\n\nBDD(Behavior Driven Development, 행위 주도 개발) 방법론을 차용한 방식으로 given - when - then 절로 해당 페이지에서 일어날 수 있는 모든 이벤트에 대해 정의한다.\n\n이 과정을 통해 구체적인 기능 명세를 할 수 있다.\n\n![](.index_images/faa7372e.png)\n\n해당 방식은 UI 기반의 기능 명세에 치중할 수 있기 때문에 API 설계가 요구된다면 API 명세를 하는것을 추천한다.\n\n> ⏰ 제한시간 : X\n\n## 결론\n\n구글 스프린트를 기반으로 피움 팀이 아이디어를 구체화하는 과정을 정리해봤다.\n\n아이디어 도출 과정에 정답은 없지만 스프린트를 처음 해본 입장에서는 참고하면 좋은 방법이라고 생각되어 기록으로 남겨봤다.\n\n## Reference\n\n[구글스프린트](https://brunch.co.kr/@brunchjwshim/90)\n[테오의 스프린트](https://velog.io/@teo/google-sprint-14)\n[Atlassian Sprint](https://www.atlassian.com/ko/agile/scrum/sprints)\nhttps://www.thesprintbook.com/the-design-sprint"}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}